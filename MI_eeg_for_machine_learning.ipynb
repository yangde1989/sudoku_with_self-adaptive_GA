{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yangde1989/sudoku_with_self-adaptive_GA/blob/master/MI_eeg_for_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "b300378d-3fee-475b-9ca0-9941851297af",
      "metadata": {
        "id": "b300378d-3fee-475b-9ca0-9941851297af"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mne_features\n",
        "from mne_features.feature_extraction import extract_features\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "2bc4fad7-0260-4d46-9725-75510b23057e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2bc4fad7-0260-4d46-9725-75510b23057e",
        "outputId": "0343b998-5b53-45bf-a4da-6d223ebc999a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "30122689-21b6-480c-88a0-ed0990542182",
      "metadata": {
        "id": "30122689-21b6-480c-88a0-ed0990542182"
      },
      "outputs": [],
      "source": [
        "data = np.load('/content/3D_training_array.npy')\n",
        "labels = np.load('/content/labels.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "e5a8818c-e7a5-4f00-9f82-e29f86fe4263",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5a8818c-e7a5-4f00-9f82-e29f86fe4263",
        "outputId": "a11d5156-6e37-4a25-8fa9-0498d7a52f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "3680 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n"
          ]
        }
      ],
      "source": [
        "# Create an info object with information about the EEG data\n",
        "ch_names = ['C3', 'Cz', 'C4']  # list of EEG channel names\n",
        "sfreq = 250  # sampling frequency\n",
        "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
        "\n",
        "# Create an EpochsArray object from the loaded data\n",
        "epochs = mne.EpochsArray(data, info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "a5d6ceec-571a-4ca7-9aaa-f5f2016137b0",
      "metadata": {
        "id": "a5d6ceec-571a-4ca7-9aaa-f5f2016137b0"
      },
      "outputs": [],
      "source": [
        "epochs.events[:,-1] = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "1bca99c9-ed1b-4929-aee7-70e0c23c3ee3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "1bca99c9-ed1b-4929-aee7-70e0c23c3ee3",
        "outputId": "b9d538f8-d4b7-4d3e-da21-2554153cc654"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<EpochsArray |  3680 events (all good), 0 - 3.996 sec, baseline off, ~84.2 MB, data loaded,\n",
              " '1': 1840>"
            ],
            "text/html": [
              "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
              "    <tr>\n",
              "        <th>Number of events</th>\n",
              "        <td>3680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Events</th>\n",
              "        \n",
              "        <td>1: 1840</td>\n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Time range</th>\n",
              "        <td>0.000 – 3.996 sec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Baseline</th>\n",
              "        <td>off</td>\n",
              "    </tr>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "epochs.set_montage('standard_1020')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e36922-22bd-4fb8-86b9-e73c5217a68c",
      "metadata": {
        "id": "a3e36922-22bd-4fb8-86b9-e73c5217a68c"
      },
      "source": [
        "**Feature extraction**`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "61f45979-920b-4082-b897-b534df5324ff",
      "metadata": {
        "id": "61f45979-920b-4082-b897-b534df5324ff"
      },
      "outputs": [],
      "source": [
        "univariate_feature_names = mne_features.feature_extraction.get_univariate_func_names()\n",
        "bivariate_feature_names = mne_features.feature_extraction.get_bivariate_func_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "146142b5-6d80-4434-8f15-1ceea7e12c18",
      "metadata": {
        "tags": [],
        "id": "146142b5-6d80-4434-8f15-1ceea7e12c18"
      },
      "outputs": [],
      "source": [
        "feature_df_list = []\n",
        "for name in univariate_feature_names:\n",
        "    feat = extract_features(data, sfreq=250, selected_funcs=[name], n_jobs=-1)\n",
        "    # print(feat.shape[-1])\n",
        "    if feat.shape[-1] == 3:\n",
        "        columns = [i + '_' + name for i in epochs.ch_names]\n",
        "        feat_df = pd.DataFrame(feat, columns=columns)\n",
        "        feature_df_list.append(feat_df)\n",
        "    else:\n",
        "        columns = []\n",
        "        for i in range(int(feat.shape[-1]/3)):\n",
        "            for j in epochs.ch_names:\n",
        "                columns.append(j + '_' + name + '_' + str(i))\n",
        "        feat_df = pd.DataFrame(feat, columns=columns)\n",
        "        feature_df_list.append(feat_df)\n",
        "    # print(feat_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "a23c4d2b-9446-42f2-89a3-960baaf20473",
      "metadata": {
        "id": "a23c4d2b-9446-42f2-89a3-960baaf20473"
      },
      "outputs": [],
      "source": [
        "unifeature_df = pd.concat(feature_df_list, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "d25aeb7b-2856-4eed-9f81-aae1cd8a0d57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "d25aeb7b-2856-4eed-9f81-aae1cd8a0d57",
        "outputId": "f56fed3d-6b65-4f1d-8ac8-95868555fa96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      C3_app_entropy  Cz_app_entropy  C4_app_entropy  C3_decorr_time  \\\n",
              "0           0.640519        0.617560        0.644461           0.020   \n",
              "1           0.671486        0.682142        0.675748           0.016   \n",
              "2           0.675393        0.688831        0.658254           0.016   \n",
              "3           0.676178        0.671084        0.686888           0.016   \n",
              "4           0.673726        0.663999        0.659038           0.016   \n",
              "...              ...             ...             ...             ...   \n",
              "3675        0.650790        0.632395        0.678886           0.020   \n",
              "3676        0.680614        0.646425        0.670222           0.020   \n",
              "3677        0.674061        0.660800        0.652781           0.020   \n",
              "3678        0.678125        0.649645        0.632297           0.020   \n",
              "3679        0.632905        0.628253        0.680774           0.020   \n",
              "\n",
              "      Cz_decorr_time  C4_decorr_time  C3_energy_freq_bands_0  \\\n",
              "0              0.024           0.016               72.166445   \n",
              "1              0.020           0.016              245.545334   \n",
              "2              0.016           0.016              168.718124   \n",
              "3              0.020           0.016              203.622553   \n",
              "4              0.020           0.016                1.748739   \n",
              "...              ...             ...                     ...   \n",
              "3675           0.020           0.020                0.528507   \n",
              "3676           0.020           0.020              306.237423   \n",
              "3677           0.020           0.020              173.831599   \n",
              "3678           0.024           0.020              104.099309   \n",
              "3679           0.024           0.020               45.716742   \n",
              "\n",
              "      Cz_energy_freq_bands_0  C4_energy_freq_bands_0  C3_energy_freq_bands_1  \\\n",
              "0                  17.927908             1442.889447             2323.168970   \n",
              "1                  48.722210              309.852570             2080.187672   \n",
              "2                  26.018248              395.747200             1933.837569   \n",
              "3                  32.952116              288.576477             1401.019400   \n",
              "4                  24.605989              329.243679             1547.622258   \n",
              "...                      ...                     ...                     ...   \n",
              "3675               32.541561              914.024088             2133.548351   \n",
              "3676               31.423662              363.036415              809.130331   \n",
              "3677               22.262733              347.590136              962.156690   \n",
              "3678               40.384043              867.145176             1687.358203   \n",
              "3679               13.883143              612.111088             1125.943339   \n",
              "\n",
              "      ...  C4_wavelet_coef_energy_3  C3_wavelet_coef_energy_4  \\\n",
              "0     ...                110.173150                  2.356601   \n",
              "1     ...                 11.119557                  2.385638   \n",
              "2     ...                  8.313311                  1.884820   \n",
              "3     ...                 32.416221                  2.501828   \n",
              "4     ...                 44.344744                  2.313896   \n",
              "...   ...                       ...                       ...   \n",
              "3675  ...                  6.513714                  1.849631   \n",
              "3676  ...                 20.617876                  2.225046   \n",
              "3677  ...                  5.075054                  1.167876   \n",
              "3678  ...                 15.707483                  1.333761   \n",
              "3679  ...                  4.198922                  1.029933   \n",
              "\n",
              "      Cz_wavelet_coef_energy_4  C4_wavelet_coef_energy_4  \\\n",
              "0                   205.843863               2162.985790   \n",
              "1                   196.625775               1404.378503   \n",
              "2                   160.667859               1293.806917   \n",
              "3                   207.608408               1726.426506   \n",
              "4                   183.732612               1665.795036   \n",
              "...                        ...                       ...   \n",
              "3675                146.568381               1140.808732   \n",
              "3676                186.291902               1469.002909   \n",
              "3677                 96.292484                966.306042   \n",
              "3678                 99.220435                921.873942   \n",
              "3679                 82.242066                631.674150   \n",
              "\n",
              "      C3_wavelet_coef_energy_5  Cz_wavelet_coef_energy_5  \\\n",
              "0                  2248.955610                149.426798   \n",
              "1                  1576.420807                100.430869   \n",
              "2                   921.856170                 62.541824   \n",
              "3                  1334.243028                165.097269   \n",
              "4                  1747.028862                 98.425123   \n",
              "...                        ...                       ...   \n",
              "3675               1931.644353                104.176955   \n",
              "3676               2386.901514                120.459300   \n",
              "3677               1373.602720                 47.161885   \n",
              "3678               2749.588322                263.177418   \n",
              "3679               1336.092095                117.370552   \n",
              "\n",
              "      C4_wavelet_coef_energy_5  C3_zero_crossings  Cz_zero_crossings  \\\n",
              "0                    18.909997                127                123   \n",
              "1                     4.714717                150                119   \n",
              "2                     8.476543                138                140   \n",
              "3                    10.717904                144                120   \n",
              "4                    13.523144                133                110   \n",
              "...                        ...                ...                ...   \n",
              "3675                 19.493342                129                126   \n",
              "3676                 22.216897                130                111   \n",
              "3677                  7.446945                135                126   \n",
              "3678                 27.010256                119                105   \n",
              "3679                  3.204657                120                105   \n",
              "\n",
              "      C4_zero_crossings  \n",
              "0                   135  \n",
              "1                   143  \n",
              "2                   139  \n",
              "3                   144  \n",
              "4                   127  \n",
              "...                 ...  \n",
              "3675                129  \n",
              "3676                131  \n",
              "3677                122  \n",
              "3678                121  \n",
              "3679                124  \n",
              "\n",
              "[3680 rows x 174 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e06c6d8-9105-4293-bf7c-d44dfe7bf29d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C3_app_entropy</th>\n",
              "      <th>Cz_app_entropy</th>\n",
              "      <th>C4_app_entropy</th>\n",
              "      <th>C3_decorr_time</th>\n",
              "      <th>Cz_decorr_time</th>\n",
              "      <th>C4_decorr_time</th>\n",
              "      <th>C3_energy_freq_bands_0</th>\n",
              "      <th>Cz_energy_freq_bands_0</th>\n",
              "      <th>C4_energy_freq_bands_0</th>\n",
              "      <th>C3_energy_freq_bands_1</th>\n",
              "      <th>...</th>\n",
              "      <th>C4_wavelet_coef_energy_3</th>\n",
              "      <th>C3_wavelet_coef_energy_4</th>\n",
              "      <th>Cz_wavelet_coef_energy_4</th>\n",
              "      <th>C4_wavelet_coef_energy_4</th>\n",
              "      <th>C3_wavelet_coef_energy_5</th>\n",
              "      <th>Cz_wavelet_coef_energy_5</th>\n",
              "      <th>C4_wavelet_coef_energy_5</th>\n",
              "      <th>C3_zero_crossings</th>\n",
              "      <th>Cz_zero_crossings</th>\n",
              "      <th>C4_zero_crossings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.640519</td>\n",
              "      <td>0.617560</td>\n",
              "      <td>0.644461</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.016</td>\n",
              "      <td>72.166445</td>\n",
              "      <td>17.927908</td>\n",
              "      <td>1442.889447</td>\n",
              "      <td>2323.168970</td>\n",
              "      <td>...</td>\n",
              "      <td>110.173150</td>\n",
              "      <td>2.356601</td>\n",
              "      <td>205.843863</td>\n",
              "      <td>2162.985790</td>\n",
              "      <td>2248.955610</td>\n",
              "      <td>149.426798</td>\n",
              "      <td>18.909997</td>\n",
              "      <td>127</td>\n",
              "      <td>123</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.671486</td>\n",
              "      <td>0.682142</td>\n",
              "      <td>0.675748</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.016</td>\n",
              "      <td>245.545334</td>\n",
              "      <td>48.722210</td>\n",
              "      <td>309.852570</td>\n",
              "      <td>2080.187672</td>\n",
              "      <td>...</td>\n",
              "      <td>11.119557</td>\n",
              "      <td>2.385638</td>\n",
              "      <td>196.625775</td>\n",
              "      <td>1404.378503</td>\n",
              "      <td>1576.420807</td>\n",
              "      <td>100.430869</td>\n",
              "      <td>4.714717</td>\n",
              "      <td>150</td>\n",
              "      <td>119</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.675393</td>\n",
              "      <td>0.688831</td>\n",
              "      <td>0.658254</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.016</td>\n",
              "      <td>168.718124</td>\n",
              "      <td>26.018248</td>\n",
              "      <td>395.747200</td>\n",
              "      <td>1933.837569</td>\n",
              "      <td>...</td>\n",
              "      <td>8.313311</td>\n",
              "      <td>1.884820</td>\n",
              "      <td>160.667859</td>\n",
              "      <td>1293.806917</td>\n",
              "      <td>921.856170</td>\n",
              "      <td>62.541824</td>\n",
              "      <td>8.476543</td>\n",
              "      <td>138</td>\n",
              "      <td>140</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.676178</td>\n",
              "      <td>0.671084</td>\n",
              "      <td>0.686888</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.016</td>\n",
              "      <td>203.622553</td>\n",
              "      <td>32.952116</td>\n",
              "      <td>288.576477</td>\n",
              "      <td>1401.019400</td>\n",
              "      <td>...</td>\n",
              "      <td>32.416221</td>\n",
              "      <td>2.501828</td>\n",
              "      <td>207.608408</td>\n",
              "      <td>1726.426506</td>\n",
              "      <td>1334.243028</td>\n",
              "      <td>165.097269</td>\n",
              "      <td>10.717904</td>\n",
              "      <td>144</td>\n",
              "      <td>120</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.673726</td>\n",
              "      <td>0.663999</td>\n",
              "      <td>0.659038</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.016</td>\n",
              "      <td>1.748739</td>\n",
              "      <td>24.605989</td>\n",
              "      <td>329.243679</td>\n",
              "      <td>1547.622258</td>\n",
              "      <td>...</td>\n",
              "      <td>44.344744</td>\n",
              "      <td>2.313896</td>\n",
              "      <td>183.732612</td>\n",
              "      <td>1665.795036</td>\n",
              "      <td>1747.028862</td>\n",
              "      <td>98.425123</td>\n",
              "      <td>13.523144</td>\n",
              "      <td>133</td>\n",
              "      <td>110</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3675</th>\n",
              "      <td>0.650790</td>\n",
              "      <td>0.632395</td>\n",
              "      <td>0.678886</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.528507</td>\n",
              "      <td>32.541561</td>\n",
              "      <td>914.024088</td>\n",
              "      <td>2133.548351</td>\n",
              "      <td>...</td>\n",
              "      <td>6.513714</td>\n",
              "      <td>1.849631</td>\n",
              "      <td>146.568381</td>\n",
              "      <td>1140.808732</td>\n",
              "      <td>1931.644353</td>\n",
              "      <td>104.176955</td>\n",
              "      <td>19.493342</td>\n",
              "      <td>129</td>\n",
              "      <td>126</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3676</th>\n",
              "      <td>0.680614</td>\n",
              "      <td>0.646425</td>\n",
              "      <td>0.670222</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>306.237423</td>\n",
              "      <td>31.423662</td>\n",
              "      <td>363.036415</td>\n",
              "      <td>809.130331</td>\n",
              "      <td>...</td>\n",
              "      <td>20.617876</td>\n",
              "      <td>2.225046</td>\n",
              "      <td>186.291902</td>\n",
              "      <td>1469.002909</td>\n",
              "      <td>2386.901514</td>\n",
              "      <td>120.459300</td>\n",
              "      <td>22.216897</td>\n",
              "      <td>130</td>\n",
              "      <td>111</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3677</th>\n",
              "      <td>0.674061</td>\n",
              "      <td>0.660800</td>\n",
              "      <td>0.652781</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>173.831599</td>\n",
              "      <td>22.262733</td>\n",
              "      <td>347.590136</td>\n",
              "      <td>962.156690</td>\n",
              "      <td>...</td>\n",
              "      <td>5.075054</td>\n",
              "      <td>1.167876</td>\n",
              "      <td>96.292484</td>\n",
              "      <td>966.306042</td>\n",
              "      <td>1373.602720</td>\n",
              "      <td>47.161885</td>\n",
              "      <td>7.446945</td>\n",
              "      <td>135</td>\n",
              "      <td>126</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3678</th>\n",
              "      <td>0.678125</td>\n",
              "      <td>0.649645</td>\n",
              "      <td>0.632297</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.020</td>\n",
              "      <td>104.099309</td>\n",
              "      <td>40.384043</td>\n",
              "      <td>867.145176</td>\n",
              "      <td>1687.358203</td>\n",
              "      <td>...</td>\n",
              "      <td>15.707483</td>\n",
              "      <td>1.333761</td>\n",
              "      <td>99.220435</td>\n",
              "      <td>921.873942</td>\n",
              "      <td>2749.588322</td>\n",
              "      <td>263.177418</td>\n",
              "      <td>27.010256</td>\n",
              "      <td>119</td>\n",
              "      <td>105</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3679</th>\n",
              "      <td>0.632905</td>\n",
              "      <td>0.628253</td>\n",
              "      <td>0.680774</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.020</td>\n",
              "      <td>45.716742</td>\n",
              "      <td>13.883143</td>\n",
              "      <td>612.111088</td>\n",
              "      <td>1125.943339</td>\n",
              "      <td>...</td>\n",
              "      <td>4.198922</td>\n",
              "      <td>1.029933</td>\n",
              "      <td>82.242066</td>\n",
              "      <td>631.674150</td>\n",
              "      <td>1336.092095</td>\n",
              "      <td>117.370552</td>\n",
              "      <td>3.204657</td>\n",
              "      <td>120</td>\n",
              "      <td>105</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3680 rows × 174 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e06c6d8-9105-4293-bf7c-d44dfe7bf29d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e06c6d8-9105-4293-bf7c-d44dfe7bf29d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e06c6d8-9105-4293-bf7c-d44dfe7bf29d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "unifeature_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "e3fa5fcf-6aef-4679-8ac7-43cd500fc10e",
      "metadata": {
        "id": "e3fa5fcf-6aef-4679-8ac7-43cd500fc10e"
      },
      "outputs": [],
      "source": [
        "feature_df_list = []\n",
        "for name in bivariate_feature_names:\n",
        "    feat = extract_features(data, sfreq=250, selected_funcs=[name], n_jobs=-1)\n",
        "    # print(feat.shape[-1])\n",
        "    if feat.shape[-1] == 3:\n",
        "        columns = [i + '_' + name for i in epochs.ch_names]\n",
        "        feat_df = pd.DataFrame(feat, columns=columns)\n",
        "        feature_df_list.append(feat_df)\n",
        "    else:\n",
        "        columns = []\n",
        "        for i in range(int(feat.shape[-1]/3)):\n",
        "            for j in epochs.ch_names:\n",
        "                columns.append(j + '_' + name + '_' + str(i))\n",
        "        feat_df = pd.DataFrame(feat, columns=columns)\n",
        "        feature_df_list.append(feat_df)\n",
        "    # print(feat_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "54400ba5-0d38-484c-99b8-2977bc086463",
      "metadata": {
        "id": "54400ba5-0d38-484c-99b8-2977bc086463"
      },
      "outputs": [],
      "source": [
        "bifeature_df = pd.concat(feature_df_list, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "8850b9b6-f4a2-4b31-a0a5-3161f25d6bc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "8850b9b6-f4a2-4b31-a0a5-3161f25d6bc6",
        "outputId": "106c196c-8601-4e5d-ac38-b4f1db991f60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      C3_max_cross_corr  Cz_max_cross_corr  C4_max_cross_corr  \\\n",
              "0              0.301838           0.382761           0.530614   \n",
              "1              0.594670           0.477668           0.561915   \n",
              "2              0.456725           0.460084           0.540452   \n",
              "3              0.469252           0.449453           0.545324   \n",
              "4              0.613831           0.437336           0.524435   \n",
              "...                 ...                ...                ...   \n",
              "3675           0.611417           0.327342           0.695534   \n",
              "3676           0.627541           0.359194           0.716564   \n",
              "3677           0.674297           0.459529           0.682174   \n",
              "3678           0.517560           0.274877           0.749784   \n",
              "3679           0.721997           0.491612           0.727941   \n",
              "\n",
              "      C3_nonlin_interdep  Cz_nonlin_interdep  C4_nonlin_interdep  \\\n",
              "0               0.186507            0.239157            0.255184   \n",
              "1               0.354749            0.271110            0.309528   \n",
              "2               0.237782            0.238831            0.261075   \n",
              "3               0.257972            0.228379            0.269267   \n",
              "4               0.341963            0.274671            0.276557   \n",
              "...                  ...                 ...                 ...   \n",
              "3675            0.375658            0.225349            0.377508   \n",
              "3676            0.252584            0.204150            0.299760   \n",
              "3677            0.346382            0.255714            0.332946   \n",
              "3678            0.209763            0.190427            0.433075   \n",
              "3679            0.358830            0.281142            0.404369   \n",
              "\n",
              "      C3_phase_lock_val  Cz_phase_lock_val  C4_phase_lock_val  \\\n",
              "0              0.366462           0.355551           0.498020   \n",
              "1              0.519167           0.355402           0.518869   \n",
              "2              0.343498           0.335374           0.450787   \n",
              "3              0.374585           0.338094           0.430481   \n",
              "4              0.485488           0.335563           0.465764   \n",
              "...                 ...                ...                ...   \n",
              "3675           0.558592           0.239790           0.524496   \n",
              "3676           0.526033           0.317309           0.604921   \n",
              "3677           0.556990           0.396871           0.622990   \n",
              "3678           0.419975           0.164724           0.653644   \n",
              "3679           0.576382           0.438318           0.645896   \n",
              "\n",
              "      C3_spect_corr_0  ...  C4_spect_corr_0  C3_spect_corr_1  Cz_spect_corr_1  \\\n",
              "0           -0.412643  ...        -0.741760     2.220446e-16         1.248209   \n",
              "1           -0.370078  ...        -0.222990     6.661338e-16         1.162136   \n",
              "2           -0.721979  ...        -0.673997     0.000000e+00         1.024471   \n",
              "3           -0.031097  ...        -0.678188     0.000000e+00         1.031057   \n",
              "4           -0.545851  ...        -0.394175     2.220446e-16         1.394066   \n",
              "...               ...  ...              ...              ...              ...   \n",
              "3675        -0.853177  ...        -0.351649     4.440892e-16         1.129838   \n",
              "3676        -0.293827  ...        -0.148749     0.000000e+00         1.086242   \n",
              "3677        -0.803365  ...         0.194760     1.942890e-16         0.805927   \n",
              "3678        -0.665705  ...        -0.175338     0.000000e+00         1.174814   \n",
              "3679        -0.003370  ...        -0.624552     0.000000e+00         1.003290   \n",
              "\n",
              "      C4_spect_corr_1  C3_time_corr_0  Cz_time_corr_0  C4_time_corr_0  \\\n",
              "0            1.751791       -0.511533       -0.568036       -0.416608   \n",
              "1            1.837864       -0.474009       -0.507618       -0.518025   \n",
              "2            1.975529       -0.554692       -0.489429       -0.454105   \n",
              "3            1.968943       -0.498291       -0.490229       -0.511404   \n",
              "4            1.605934       -0.486548       -0.439165       -0.571221   \n",
              "...               ...             ...             ...             ...   \n",
              "3675         1.870162       -0.359536       -0.727777       -0.378293   \n",
              "3676         1.913758       -0.255482       -0.732049       -0.471619   \n",
              "3677         2.194073       -0.381564       -0.661388       -0.440936   \n",
              "3678         1.825186       -0.501223       -0.743537       -0.205955   \n",
              "3679         1.996710       -0.454426       -0.648569       -0.383299   \n",
              "\n",
              "      C3_time_corr_1  Cz_time_corr_1  C4_time_corr_1  \n",
              "0       0.000000e+00        1.411157        1.588843  \n",
              "1       2.220446e-16        1.473347        1.526653  \n",
              "2       0.000000e+00        1.441379        1.558621  \n",
              "3       6.661338e-16        1.487670        1.512330  \n",
              "4       2.220446e-16        1.423263        1.576737  \n",
              "...              ...             ...             ...  \n",
              "3675    2.220446e-16        1.271898        1.728102  \n",
              "3676    2.220446e-16        1.228724        1.771276  \n",
              "3677    0.000000e+00        1.334322        1.665678  \n",
              "3678    4.440892e-16        1.189371        1.810629  \n",
              "3679    4.440892e-16        1.344877        1.655123  \n",
              "\n",
              "[3680 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b7efb9b-4a0e-4887-82f6-0cacde8216ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C3_max_cross_corr</th>\n",
              "      <th>Cz_max_cross_corr</th>\n",
              "      <th>C4_max_cross_corr</th>\n",
              "      <th>C3_nonlin_interdep</th>\n",
              "      <th>Cz_nonlin_interdep</th>\n",
              "      <th>C4_nonlin_interdep</th>\n",
              "      <th>C3_phase_lock_val</th>\n",
              "      <th>Cz_phase_lock_val</th>\n",
              "      <th>C4_phase_lock_val</th>\n",
              "      <th>C3_spect_corr_0</th>\n",
              "      <th>...</th>\n",
              "      <th>C4_spect_corr_0</th>\n",
              "      <th>C3_spect_corr_1</th>\n",
              "      <th>Cz_spect_corr_1</th>\n",
              "      <th>C4_spect_corr_1</th>\n",
              "      <th>C3_time_corr_0</th>\n",
              "      <th>Cz_time_corr_0</th>\n",
              "      <th>C4_time_corr_0</th>\n",
              "      <th>C3_time_corr_1</th>\n",
              "      <th>Cz_time_corr_1</th>\n",
              "      <th>C4_time_corr_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.301838</td>\n",
              "      <td>0.382761</td>\n",
              "      <td>0.530614</td>\n",
              "      <td>0.186507</td>\n",
              "      <td>0.239157</td>\n",
              "      <td>0.255184</td>\n",
              "      <td>0.366462</td>\n",
              "      <td>0.355551</td>\n",
              "      <td>0.498020</td>\n",
              "      <td>-0.412643</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.741760</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.248209</td>\n",
              "      <td>1.751791</td>\n",
              "      <td>-0.511533</td>\n",
              "      <td>-0.568036</td>\n",
              "      <td>-0.416608</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.411157</td>\n",
              "      <td>1.588843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.594670</td>\n",
              "      <td>0.477668</td>\n",
              "      <td>0.561915</td>\n",
              "      <td>0.354749</td>\n",
              "      <td>0.271110</td>\n",
              "      <td>0.309528</td>\n",
              "      <td>0.519167</td>\n",
              "      <td>0.355402</td>\n",
              "      <td>0.518869</td>\n",
              "      <td>-0.370078</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.222990</td>\n",
              "      <td>6.661338e-16</td>\n",
              "      <td>1.162136</td>\n",
              "      <td>1.837864</td>\n",
              "      <td>-0.474009</td>\n",
              "      <td>-0.507618</td>\n",
              "      <td>-0.518025</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.473347</td>\n",
              "      <td>1.526653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.456725</td>\n",
              "      <td>0.460084</td>\n",
              "      <td>0.540452</td>\n",
              "      <td>0.237782</td>\n",
              "      <td>0.238831</td>\n",
              "      <td>0.261075</td>\n",
              "      <td>0.343498</td>\n",
              "      <td>0.335374</td>\n",
              "      <td>0.450787</td>\n",
              "      <td>-0.721979</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.673997</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.024471</td>\n",
              "      <td>1.975529</td>\n",
              "      <td>-0.554692</td>\n",
              "      <td>-0.489429</td>\n",
              "      <td>-0.454105</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.441379</td>\n",
              "      <td>1.558621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.469252</td>\n",
              "      <td>0.449453</td>\n",
              "      <td>0.545324</td>\n",
              "      <td>0.257972</td>\n",
              "      <td>0.228379</td>\n",
              "      <td>0.269267</td>\n",
              "      <td>0.374585</td>\n",
              "      <td>0.338094</td>\n",
              "      <td>0.430481</td>\n",
              "      <td>-0.031097</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.678188</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.031057</td>\n",
              "      <td>1.968943</td>\n",
              "      <td>-0.498291</td>\n",
              "      <td>-0.490229</td>\n",
              "      <td>-0.511404</td>\n",
              "      <td>6.661338e-16</td>\n",
              "      <td>1.487670</td>\n",
              "      <td>1.512330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.613831</td>\n",
              "      <td>0.437336</td>\n",
              "      <td>0.524435</td>\n",
              "      <td>0.341963</td>\n",
              "      <td>0.274671</td>\n",
              "      <td>0.276557</td>\n",
              "      <td>0.485488</td>\n",
              "      <td>0.335563</td>\n",
              "      <td>0.465764</td>\n",
              "      <td>-0.545851</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.394175</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.394066</td>\n",
              "      <td>1.605934</td>\n",
              "      <td>-0.486548</td>\n",
              "      <td>-0.439165</td>\n",
              "      <td>-0.571221</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.423263</td>\n",
              "      <td>1.576737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3675</th>\n",
              "      <td>0.611417</td>\n",
              "      <td>0.327342</td>\n",
              "      <td>0.695534</td>\n",
              "      <td>0.375658</td>\n",
              "      <td>0.225349</td>\n",
              "      <td>0.377508</td>\n",
              "      <td>0.558592</td>\n",
              "      <td>0.239790</td>\n",
              "      <td>0.524496</td>\n",
              "      <td>-0.853177</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.351649</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>1.129838</td>\n",
              "      <td>1.870162</td>\n",
              "      <td>-0.359536</td>\n",
              "      <td>-0.727777</td>\n",
              "      <td>-0.378293</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.271898</td>\n",
              "      <td>1.728102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3676</th>\n",
              "      <td>0.627541</td>\n",
              "      <td>0.359194</td>\n",
              "      <td>0.716564</td>\n",
              "      <td>0.252584</td>\n",
              "      <td>0.204150</td>\n",
              "      <td>0.299760</td>\n",
              "      <td>0.526033</td>\n",
              "      <td>0.317309</td>\n",
              "      <td>0.604921</td>\n",
              "      <td>-0.293827</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.148749</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.086242</td>\n",
              "      <td>1.913758</td>\n",
              "      <td>-0.255482</td>\n",
              "      <td>-0.732049</td>\n",
              "      <td>-0.471619</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.228724</td>\n",
              "      <td>1.771276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3677</th>\n",
              "      <td>0.674297</td>\n",
              "      <td>0.459529</td>\n",
              "      <td>0.682174</td>\n",
              "      <td>0.346382</td>\n",
              "      <td>0.255714</td>\n",
              "      <td>0.332946</td>\n",
              "      <td>0.556990</td>\n",
              "      <td>0.396871</td>\n",
              "      <td>0.622990</td>\n",
              "      <td>-0.803365</td>\n",
              "      <td>...</td>\n",
              "      <td>0.194760</td>\n",
              "      <td>1.942890e-16</td>\n",
              "      <td>0.805927</td>\n",
              "      <td>2.194073</td>\n",
              "      <td>-0.381564</td>\n",
              "      <td>-0.661388</td>\n",
              "      <td>-0.440936</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.334322</td>\n",
              "      <td>1.665678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3678</th>\n",
              "      <td>0.517560</td>\n",
              "      <td>0.274877</td>\n",
              "      <td>0.749784</td>\n",
              "      <td>0.209763</td>\n",
              "      <td>0.190427</td>\n",
              "      <td>0.433075</td>\n",
              "      <td>0.419975</td>\n",
              "      <td>0.164724</td>\n",
              "      <td>0.653644</td>\n",
              "      <td>-0.665705</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.175338</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.174814</td>\n",
              "      <td>1.825186</td>\n",
              "      <td>-0.501223</td>\n",
              "      <td>-0.743537</td>\n",
              "      <td>-0.205955</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>1.189371</td>\n",
              "      <td>1.810629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3679</th>\n",
              "      <td>0.721997</td>\n",
              "      <td>0.491612</td>\n",
              "      <td>0.727941</td>\n",
              "      <td>0.358830</td>\n",
              "      <td>0.281142</td>\n",
              "      <td>0.404369</td>\n",
              "      <td>0.576382</td>\n",
              "      <td>0.438318</td>\n",
              "      <td>0.645896</td>\n",
              "      <td>-0.003370</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.624552</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.003290</td>\n",
              "      <td>1.996710</td>\n",
              "      <td>-0.454426</td>\n",
              "      <td>-0.648569</td>\n",
              "      <td>-0.383299</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>1.344877</td>\n",
              "      <td>1.655123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3680 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b7efb9b-4a0e-4887-82f6-0cacde8216ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b7efb9b-4a0e-4887-82f6-0cacde8216ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b7efb9b-4a0e-4887-82f6-0cacde8216ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "bifeature_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "dc7a906c-8910-4fd8-9272-9c0120b69982",
      "metadata": {
        "id": "dc7a906c-8910-4fd8-9272-9c0120b69982"
      },
      "outputs": [],
      "source": [
        "feature_df = pd.concat([unifeature_df, bifeature_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "cd88cdf0-1d52-4518-9ae3-09a45f293d41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "cd88cdf0-1d52-4518-9ae3-09a45f293d41",
        "outputId": "de2f6c39-4c9e-40da-bc06-fa3d57e1f5b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      C3_app_entropy  Cz_app_entropy  C4_app_entropy  C3_decorr_time  \\\n",
              "0           0.640519        0.617560        0.644461           0.020   \n",
              "1           0.671486        0.682142        0.675748           0.016   \n",
              "2           0.675393        0.688831        0.658254           0.016   \n",
              "3           0.676178        0.671084        0.686888           0.016   \n",
              "4           0.673726        0.663999        0.659038           0.016   \n",
              "...              ...             ...             ...             ...   \n",
              "3675        0.650790        0.632395        0.678886           0.020   \n",
              "3676        0.680614        0.646425        0.670222           0.020   \n",
              "3677        0.674061        0.660800        0.652781           0.020   \n",
              "3678        0.678125        0.649645        0.632297           0.020   \n",
              "3679        0.632905        0.628253        0.680774           0.020   \n",
              "\n",
              "      Cz_decorr_time  C4_decorr_time  C3_energy_freq_bands_0  \\\n",
              "0              0.024           0.016               72.166445   \n",
              "1              0.020           0.016              245.545334   \n",
              "2              0.016           0.016              168.718124   \n",
              "3              0.020           0.016              203.622553   \n",
              "4              0.020           0.016                1.748739   \n",
              "...              ...             ...                     ...   \n",
              "3675           0.020           0.020                0.528507   \n",
              "3676           0.020           0.020              306.237423   \n",
              "3677           0.020           0.020              173.831599   \n",
              "3678           0.024           0.020              104.099309   \n",
              "3679           0.024           0.020               45.716742   \n",
              "\n",
              "      Cz_energy_freq_bands_0  C4_energy_freq_bands_0  C3_energy_freq_bands_1  \\\n",
              "0                  17.927908             1442.889447             2323.168970   \n",
              "1                  48.722210              309.852570             2080.187672   \n",
              "2                  26.018248              395.747200             1933.837569   \n",
              "3                  32.952116              288.576477             1401.019400   \n",
              "4                  24.605989              329.243679             1547.622258   \n",
              "...                      ...                     ...                     ...   \n",
              "3675               32.541561              914.024088             2133.548351   \n",
              "3676               31.423662              363.036415              809.130331   \n",
              "3677               22.262733              347.590136              962.156690   \n",
              "3678               40.384043              867.145176             1687.358203   \n",
              "3679               13.883143              612.111088             1125.943339   \n",
              "\n",
              "      ...  C4_spect_corr_0  C3_spect_corr_1  Cz_spect_corr_1  C4_spect_corr_1  \\\n",
              "0     ...        -0.741760     2.220446e-16         1.248209         1.751791   \n",
              "1     ...        -0.222990     6.661338e-16         1.162136         1.837864   \n",
              "2     ...        -0.673997     0.000000e+00         1.024471         1.975529   \n",
              "3     ...        -0.678188     0.000000e+00         1.031057         1.968943   \n",
              "4     ...        -0.394175     2.220446e-16         1.394066         1.605934   \n",
              "...   ...              ...              ...              ...              ...   \n",
              "3675  ...        -0.351649     4.440892e-16         1.129838         1.870162   \n",
              "3676  ...        -0.148749     0.000000e+00         1.086242         1.913758   \n",
              "3677  ...         0.194760     1.942890e-16         0.805927         2.194073   \n",
              "3678  ...        -0.175338     0.000000e+00         1.174814         1.825186   \n",
              "3679  ...        -0.624552     0.000000e+00         1.003290         1.996710   \n",
              "\n",
              "      C3_time_corr_0  Cz_time_corr_0  C4_time_corr_0  C3_time_corr_1  \\\n",
              "0          -0.511533       -0.568036       -0.416608    0.000000e+00   \n",
              "1          -0.474009       -0.507618       -0.518025    2.220446e-16   \n",
              "2          -0.554692       -0.489429       -0.454105    0.000000e+00   \n",
              "3          -0.498291       -0.490229       -0.511404    6.661338e-16   \n",
              "4          -0.486548       -0.439165       -0.571221    2.220446e-16   \n",
              "...              ...             ...             ...             ...   \n",
              "3675       -0.359536       -0.727777       -0.378293    2.220446e-16   \n",
              "3676       -0.255482       -0.732049       -0.471619    2.220446e-16   \n",
              "3677       -0.381564       -0.661388       -0.440936    0.000000e+00   \n",
              "3678       -0.501223       -0.743537       -0.205955    4.440892e-16   \n",
              "3679       -0.454426       -0.648569       -0.383299    4.440892e-16   \n",
              "\n",
              "      Cz_time_corr_1  C4_time_corr_1  \n",
              "0           1.411157        1.588843  \n",
              "1           1.473347        1.526653  \n",
              "2           1.441379        1.558621  \n",
              "3           1.487670        1.512330  \n",
              "4           1.423263        1.576737  \n",
              "...              ...             ...  \n",
              "3675        1.271898        1.728102  \n",
              "3676        1.228724        1.771276  \n",
              "3677        1.334322        1.665678  \n",
              "3678        1.189371        1.810629  \n",
              "3679        1.344877        1.655123  \n",
              "\n",
              "[3680 rows x 195 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d4b01ef-1307-4635-a8df-06237570e2ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C3_app_entropy</th>\n",
              "      <th>Cz_app_entropy</th>\n",
              "      <th>C4_app_entropy</th>\n",
              "      <th>C3_decorr_time</th>\n",
              "      <th>Cz_decorr_time</th>\n",
              "      <th>C4_decorr_time</th>\n",
              "      <th>C3_energy_freq_bands_0</th>\n",
              "      <th>Cz_energy_freq_bands_0</th>\n",
              "      <th>C4_energy_freq_bands_0</th>\n",
              "      <th>C3_energy_freq_bands_1</th>\n",
              "      <th>...</th>\n",
              "      <th>C4_spect_corr_0</th>\n",
              "      <th>C3_spect_corr_1</th>\n",
              "      <th>Cz_spect_corr_1</th>\n",
              "      <th>C4_spect_corr_1</th>\n",
              "      <th>C3_time_corr_0</th>\n",
              "      <th>Cz_time_corr_0</th>\n",
              "      <th>C4_time_corr_0</th>\n",
              "      <th>C3_time_corr_1</th>\n",
              "      <th>Cz_time_corr_1</th>\n",
              "      <th>C4_time_corr_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.640519</td>\n",
              "      <td>0.617560</td>\n",
              "      <td>0.644461</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.016</td>\n",
              "      <td>72.166445</td>\n",
              "      <td>17.927908</td>\n",
              "      <td>1442.889447</td>\n",
              "      <td>2323.168970</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.741760</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.248209</td>\n",
              "      <td>1.751791</td>\n",
              "      <td>-0.511533</td>\n",
              "      <td>-0.568036</td>\n",
              "      <td>-0.416608</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.411157</td>\n",
              "      <td>1.588843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.671486</td>\n",
              "      <td>0.682142</td>\n",
              "      <td>0.675748</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.016</td>\n",
              "      <td>245.545334</td>\n",
              "      <td>48.722210</td>\n",
              "      <td>309.852570</td>\n",
              "      <td>2080.187672</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.222990</td>\n",
              "      <td>6.661338e-16</td>\n",
              "      <td>1.162136</td>\n",
              "      <td>1.837864</td>\n",
              "      <td>-0.474009</td>\n",
              "      <td>-0.507618</td>\n",
              "      <td>-0.518025</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.473347</td>\n",
              "      <td>1.526653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.675393</td>\n",
              "      <td>0.688831</td>\n",
              "      <td>0.658254</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.016</td>\n",
              "      <td>168.718124</td>\n",
              "      <td>26.018248</td>\n",
              "      <td>395.747200</td>\n",
              "      <td>1933.837569</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.673997</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.024471</td>\n",
              "      <td>1.975529</td>\n",
              "      <td>-0.554692</td>\n",
              "      <td>-0.489429</td>\n",
              "      <td>-0.454105</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.441379</td>\n",
              "      <td>1.558621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.676178</td>\n",
              "      <td>0.671084</td>\n",
              "      <td>0.686888</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.016</td>\n",
              "      <td>203.622553</td>\n",
              "      <td>32.952116</td>\n",
              "      <td>288.576477</td>\n",
              "      <td>1401.019400</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.678188</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.031057</td>\n",
              "      <td>1.968943</td>\n",
              "      <td>-0.498291</td>\n",
              "      <td>-0.490229</td>\n",
              "      <td>-0.511404</td>\n",
              "      <td>6.661338e-16</td>\n",
              "      <td>1.487670</td>\n",
              "      <td>1.512330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.673726</td>\n",
              "      <td>0.663999</td>\n",
              "      <td>0.659038</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.016</td>\n",
              "      <td>1.748739</td>\n",
              "      <td>24.605989</td>\n",
              "      <td>329.243679</td>\n",
              "      <td>1547.622258</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.394175</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.394066</td>\n",
              "      <td>1.605934</td>\n",
              "      <td>-0.486548</td>\n",
              "      <td>-0.439165</td>\n",
              "      <td>-0.571221</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.423263</td>\n",
              "      <td>1.576737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3675</th>\n",
              "      <td>0.650790</td>\n",
              "      <td>0.632395</td>\n",
              "      <td>0.678886</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.528507</td>\n",
              "      <td>32.541561</td>\n",
              "      <td>914.024088</td>\n",
              "      <td>2133.548351</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.351649</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>1.129838</td>\n",
              "      <td>1.870162</td>\n",
              "      <td>-0.359536</td>\n",
              "      <td>-0.727777</td>\n",
              "      <td>-0.378293</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.271898</td>\n",
              "      <td>1.728102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3676</th>\n",
              "      <td>0.680614</td>\n",
              "      <td>0.646425</td>\n",
              "      <td>0.670222</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>306.237423</td>\n",
              "      <td>31.423662</td>\n",
              "      <td>363.036415</td>\n",
              "      <td>809.130331</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.148749</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.086242</td>\n",
              "      <td>1.913758</td>\n",
              "      <td>-0.255482</td>\n",
              "      <td>-0.732049</td>\n",
              "      <td>-0.471619</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>1.228724</td>\n",
              "      <td>1.771276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3677</th>\n",
              "      <td>0.674061</td>\n",
              "      <td>0.660800</td>\n",
              "      <td>0.652781</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>173.831599</td>\n",
              "      <td>22.262733</td>\n",
              "      <td>347.590136</td>\n",
              "      <td>962.156690</td>\n",
              "      <td>...</td>\n",
              "      <td>0.194760</td>\n",
              "      <td>1.942890e-16</td>\n",
              "      <td>0.805927</td>\n",
              "      <td>2.194073</td>\n",
              "      <td>-0.381564</td>\n",
              "      <td>-0.661388</td>\n",
              "      <td>-0.440936</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.334322</td>\n",
              "      <td>1.665678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3678</th>\n",
              "      <td>0.678125</td>\n",
              "      <td>0.649645</td>\n",
              "      <td>0.632297</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.020</td>\n",
              "      <td>104.099309</td>\n",
              "      <td>40.384043</td>\n",
              "      <td>867.145176</td>\n",
              "      <td>1687.358203</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.175338</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.174814</td>\n",
              "      <td>1.825186</td>\n",
              "      <td>-0.501223</td>\n",
              "      <td>-0.743537</td>\n",
              "      <td>-0.205955</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>1.189371</td>\n",
              "      <td>1.810629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3679</th>\n",
              "      <td>0.632905</td>\n",
              "      <td>0.628253</td>\n",
              "      <td>0.680774</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.020</td>\n",
              "      <td>45.716742</td>\n",
              "      <td>13.883143</td>\n",
              "      <td>612.111088</td>\n",
              "      <td>1125.943339</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.624552</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.003290</td>\n",
              "      <td>1.996710</td>\n",
              "      <td>-0.454426</td>\n",
              "      <td>-0.648569</td>\n",
              "      <td>-0.383299</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>1.344877</td>\n",
              "      <td>1.655123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3680 rows × 195 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d4b01ef-1307-4635-a8df-06237570e2ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d4b01ef-1307-4635-a8df-06237570e2ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d4b01ef-1307-4635-a8df-06237570e2ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "feature_df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "7764bc05-cda2-498b-ae40-abbc2964a01e",
      "metadata": {
        "id": "7764bc05-cda2-498b-ae40-abbc2964a01e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "54ca4a88-ccb5-453c-9711-f248136001d6",
      "metadata": {
        "id": "54ca4a88-ccb5-453c-9711-f248136001d6"
      },
      "source": [
        "**Feature selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "a6626353-21dc-4efd-a8ec-c3f868db9c99",
      "metadata": {
        "id": "a6626353-21dc-4efd-a8ec-c3f868db9c99"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from mrmr import mrmr_classif"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2acdb7a8-2e1c-4359-8122-22c86da21dda",
      "metadata": {
        "id": "2acdb7a8-2e1c-4359-8122-22c86da21dda"
      },
      "source": [
        "Lasso regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "96b23cc6-1f89-41cd-afde-500ba926ce1a",
      "metadata": {
        "id": "96b23cc6-1f89-41cd-afde-500ba926ce1a"
      },
      "outputs": [],
      "source": [
        "lasso = Lasso(alpha=0.1)\n",
        "\n",
        "# Fit the lasso regression\n",
        "lasso.fit(feature_df, labels)\n",
        "\n",
        "# Get the coefficients\n",
        "lasso_coef = lasso.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "d305d938-2f0c-461c-ac64-e2ab7f7433a2",
      "metadata": {
        "id": "d305d938-2f0c-461c-ac64-e2ab7f7433a2"
      },
      "outputs": [],
      "source": [
        "non_zero_coef = lasso_coef[lasso_coef!=0].tolist()\n",
        "\n",
        "non_zero_coef.sort(key=abs, reverse=True)\n",
        "\n",
        "indices = []\n",
        "for value in non_zero_coef:\n",
        "    index = np.where(lasso_coef==value)\n",
        "    indices.append(index[0].item())\n",
        "\n",
        "lasso_selected_features =[feature_df.columns.to_list()[i] for i in indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "196dba9b-e31c-435c-9a38-13098074d9ef",
      "metadata": {
        "id": "196dba9b-e31c-435c-9a38-13098074d9ef"
      },
      "source": [
        "MRMR feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "1477ae7c-b449-4ac4-949d-f4e149b0756b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1477ae7c-b449-4ac4-949d-f4e149b0756b",
        "outputId": "cadd495b-f04a-41b6-c82f-1246ba0e38ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.44it/s]\n"
          ]
        }
      ],
      "source": [
        "mrmr_selected_features = mrmr_classif(X=feature_df, y=labels, K=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "e45045b8-813e-4083-90ed-8f9ae3e4a68d",
      "metadata": {
        "id": "e45045b8-813e-4083-90ed-8f9ae3e4a68d"
      },
      "outputs": [],
      "source": [
        "selected_features = mrmr_selected_features\n",
        "# selected_features = []\n",
        "# for i in mrmr_selected_features[:30]:\n",
        "#     if i in lasso_selected_features[:30]:\n",
        "#         selected_features.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "f7e238a4-6817-4502-8e3a-7374cf6ec9c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7e238a4-6817-4502-8e3a-7374cf6ec9c8",
        "outputId": "613e48ab-8728-4d28-ca96-aea8f9294007"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C3_time_corr_0',\n",
              " 'C4_energy_freq_bands_0',\n",
              " 'C4_time_corr_0',\n",
              " 'C4_quantile',\n",
              " 'C3_kurtosis',\n",
              " 'C4_line_length',\n",
              " 'C3_svd_fisher_info',\n",
              " 'Cz_teager_kaiser_energy_11',\n",
              " 'C3_quantile',\n",
              " 'C3_energy_freq_bands_4']"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "selected_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "a2ecd0b0-483a-4a8f-9864-4041ada56975",
      "metadata": {
        "id": "a2ecd0b0-483a-4a8f-9864-4041ada56975"
      },
      "outputs": [],
      "source": [
        "X_selected = feature_df.loc[:,selected_features]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bef4dfdb-3511-482d-9979-a0c26c36d31f",
      "metadata": {
        "id": "bef4dfdb-3511-482d-9979-a0c26c36d31f"
      },
      "source": [
        "**Normalize feature values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "8e1dee84-85e5-4191-91c3-c6622fe0652b",
      "metadata": {
        "id": "8e1dee84-85e5-4191-91c3-c6622fe0652b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_selected = scaler.fit_transform(X_selected)\n",
        "\n",
        "X_selected.shape\n",
        "\n",
        "y = labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbab833a-3628-47ef-a4d7-c2e1370cbb50",
      "metadata": {
        "id": "bbab833a-3628-47ef-a4d7-c2e1370cbb50"
      },
      "source": [
        "**Classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "9da3c569-4328-4725-869f-d53564f83b56",
      "metadata": {
        "id": "9da3c569-4328-4725-869f-d53564f83b56"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import classification_report, cohen_kappa_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "b0d82a6b-3b98-4383-b318-d6aa4a98de19",
      "metadata": {
        "id": "b0d82a6b-3b98-4383-b318-d6aa4a98de19"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0b4c86d-9b84-4f95-aec7-f0e7510ae3b8",
      "metadata": {
        "id": "b0b4c86d-9b84-4f95-aec7-f0e7510ae3b8"
      },
      "source": [
        "Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "8001974d-ea9d-454a-8ddd-bdf6f1f30d9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "8001974d-ea9d-454a-8ddd-bdf6f1f30d9a",
        "outputId": "be665f22-03cc-4665-ac6b-6d1126768725"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "e139c2e6-b142-4155-b1c8-693acec8e086",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "e139c2e6-b142-4155-b1c8-693acec8e086",
        "outputId": "3148d24e-a9c4-4cca-9292-01a84ea12d6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0           1  accuracy    macro avg  weighted avg\n",
              "precision    0.687266    0.680702  0.683877     0.683984      0.683966\n",
              "recall       0.668488    0.699099  0.683877     0.683794      0.683877\n",
              "f1-score     0.677747    0.689778  0.683877     0.683762      0.683795\n",
              "support    549.000000  555.000000  0.683877  1104.000000   1104.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5751cbb7-0aad-4edd-86cc-c8d1c174016d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.687266</td>\n",
              "      <td>0.680702</td>\n",
              "      <td>0.683877</td>\n",
              "      <td>0.683984</td>\n",
              "      <td>0.683966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.668488</td>\n",
              "      <td>0.699099</td>\n",
              "      <td>0.683877</td>\n",
              "      <td>0.683794</td>\n",
              "      <td>0.683877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.677747</td>\n",
              "      <td>0.689778</td>\n",
              "      <td>0.683877</td>\n",
              "      <td>0.683762</td>\n",
              "      <td>0.683795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>555.000000</td>\n",
              "      <td>0.683877</td>\n",
              "      <td>1104.000000</td>\n",
              "      <td>1104.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5751cbb7-0aad-4edd-86cc-c8d1c174016d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5751cbb7-0aad-4edd-86cc-c8d1c174016d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5751cbb7-0aad-4edd-86cc-c8d1c174016d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "y_pred_lr = lr.predict(X_test)\n",
        "report_lr = classification_report(y_test,y_pred_lr,  output_dict=True)\n",
        "report_lr = pd.DataFrame(report_lr)\n",
        "kappa_lr = cohen_kappa_score(y_test,y_pred_lr)\n",
        "report_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "a556c9ce-951d-4f57-a2c5-e1d97c4b3208",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a556c9ce-951d-4f57-a2c5-e1d97c4b3208",
        "outputId": "1c1e6951-3867-4212-a484-892e1d85d70a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.65"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "cross = cross_val_score(lr, X_selected, y, cv=10)\n",
        "cross.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5223fc87-18ff-43ea-b9a6-80c2e3b35b39",
      "metadata": {
        "id": "5223fc87-18ff-43ea-b9a6-80c2e3b35b39"
      },
      "source": [
        "Gaussian Naïve Bayes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "91cf23f9-864d-4e75-98ac-f51bbb9ec070",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "91cf23f9-864d-4e75-98ac-f51bbb9ec070",
        "outputId": "2f8d0187-8bc2-42cc-bb26-8462bba81bf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "GNB = GaussianNB()\n",
        "GNB.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "d4d854b6-1c9e-4bf1-824d-056e47cc97b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "d4d854b6-1c9e-4bf1-824d-056e47cc97b4",
        "outputId": "03afc087-687d-4359-94df-7cb3d42c7bde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0           1  accuracy    macro avg  weighted avg\n",
              "precision    0.582895    0.691860  0.616848     0.637378      0.637674\n",
              "recall       0.806922    0.428829  0.616848     0.617875      0.616848\n",
              "f1-score     0.676853    0.529477  0.616848     0.603165      0.602764\n",
              "support    549.000000  555.000000  0.616848  1104.000000   1104.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d066e22-fd86-43fb-9cc0-d864676ee412\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.582895</td>\n",
              "      <td>0.691860</td>\n",
              "      <td>0.616848</td>\n",
              "      <td>0.637378</td>\n",
              "      <td>0.637674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.806922</td>\n",
              "      <td>0.428829</td>\n",
              "      <td>0.616848</td>\n",
              "      <td>0.617875</td>\n",
              "      <td>0.616848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.676853</td>\n",
              "      <td>0.529477</td>\n",
              "      <td>0.616848</td>\n",
              "      <td>0.603165</td>\n",
              "      <td>0.602764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>555.000000</td>\n",
              "      <td>0.616848</td>\n",
              "      <td>1104.000000</td>\n",
              "      <td>1104.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d066e22-fd86-43fb-9cc0-d864676ee412')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d066e22-fd86-43fb-9cc0-d864676ee412 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d066e22-fd86-43fb-9cc0-d864676ee412');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "y_pred_GNB = GNB.predict(X_test)\n",
        "report_GNB = classification_report(y_test,y_pred_GNB,  output_dict=True)\n",
        "report_GNB = pd.DataFrame(report_GNB)\n",
        "report_GNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "50eaa56e-3651-4556-afd8-a4377ab79178",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50eaa56e-3651-4556-afd8-a4377ab79178",
        "outputId": "9d24d6df-5485-434b-df9c-62605d9b2e2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5956521739130436"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "cross = cross_val_score(GNB, X_selected, y, cv=10)\n",
        "cross.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a3ac1eb-f384-4ae3-a4f7-43988ea6836a",
      "metadata": {
        "id": "4a3ac1eb-f384-4ae3-a4f7-43988ea6836a"
      },
      "source": [
        "K-nearest neighbor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "272132fd-5e21-49fd-ae5c-f28274515439",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "272132fd-5e21-49fd-ae5c-f28274515439",
        "outputId": "32895967-b4c8-4994-9ce5-f5928fb73241"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=15)"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=15)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors=15)\n",
        "KNN.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "c61196db-11ef-4800-8512-3629eb3d7240",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "c61196db-11ef-4800-8512-3629eb3d7240",
        "outputId": "d553815c-0b3d-4481-879a-4799b0db5286"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0           1  accuracy    macro avg  weighted avg\n",
              "precision    0.666052    0.665480  0.665761     0.665766      0.665764\n",
              "recall       0.657559    0.673874  0.665761     0.665717      0.665761\n",
              "f1-score     0.661778    0.669651  0.665761     0.665715      0.665736\n",
              "support    549.000000  555.000000  0.665761  1104.000000   1104.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4781826-46ad-4566-8c44-ac95c762b880\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.666052</td>\n",
              "      <td>0.665480</td>\n",
              "      <td>0.665761</td>\n",
              "      <td>0.665766</td>\n",
              "      <td>0.665764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.657559</td>\n",
              "      <td>0.673874</td>\n",
              "      <td>0.665761</td>\n",
              "      <td>0.665717</td>\n",
              "      <td>0.665761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.661778</td>\n",
              "      <td>0.669651</td>\n",
              "      <td>0.665761</td>\n",
              "      <td>0.665715</td>\n",
              "      <td>0.665736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>555.000000</td>\n",
              "      <td>0.665761</td>\n",
              "      <td>1104.000000</td>\n",
              "      <td>1104.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4781826-46ad-4566-8c44-ac95c762b880')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4781826-46ad-4566-8c44-ac95c762b880 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4781826-46ad-4566-8c44-ac95c762b880');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "y_pred_knn = KNN.predict(X_test)\n",
        "report_knn = classification_report(y_test,y_pred_knn,  output_dict=True)\n",
        "report_knn = pd.DataFrame(report_knn)\n",
        "report_knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "0e0d515a-166a-47bb-992e-1476dd40f405",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e0d515a-166a-47bb-992e-1476dd40f405",
        "outputId": "bb448e25-abc8-44d2-ea21-c2fff4f2586f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6236413043478262"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "cross = cross_val_score(KNN, X_selected, y, cv=10)\n",
        "cross.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbb1f8c1-4fbe-4af8-935e-87652bdc38e2",
      "metadata": {
        "id": "dbb1f8c1-4fbe-4af8-935e-87652bdc38e2"
      },
      "source": [
        "Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "ac0765e2-25c9-4de2-8b24-b1e7e4e87c05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ac0765e2-25c9-4de2-8b24-b1e7e4e87c05",
        "outputId": "cbf38cf1-8c95-4193-9c70-fb8112766ae2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron()"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "ptron = Perceptron()\n",
        "ptron.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "52ba29c0-f94a-4bfb-b017-78bf58660dae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "52ba29c0-f94a-4bfb-b017-78bf58660dae",
        "outputId": "169deb88-1d04-4076-b828-b6856c3a324d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0           1  accuracy    macro avg  weighted avg\n",
              "precision    0.821782    0.575388  0.620471     0.698585      0.697916\n",
              "recall       0.302368    0.935135  0.620471     0.618752      0.620471\n",
              "f1-score     0.442077    0.712423  0.620471     0.577250      0.577985\n",
              "support    549.000000  555.000000  0.620471  1104.000000   1104.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed2cda65-ba47-49a9-bfca-79ae1049cd95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.821782</td>\n",
              "      <td>0.575388</td>\n",
              "      <td>0.620471</td>\n",
              "      <td>0.698585</td>\n",
              "      <td>0.697916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.302368</td>\n",
              "      <td>0.935135</td>\n",
              "      <td>0.620471</td>\n",
              "      <td>0.618752</td>\n",
              "      <td>0.620471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.442077</td>\n",
              "      <td>0.712423</td>\n",
              "      <td>0.620471</td>\n",
              "      <td>0.577250</td>\n",
              "      <td>0.577985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>555.000000</td>\n",
              "      <td>0.620471</td>\n",
              "      <td>1104.000000</td>\n",
              "      <td>1104.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed2cda65-ba47-49a9-bfca-79ae1049cd95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed2cda65-ba47-49a9-bfca-79ae1049cd95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed2cda65-ba47-49a9-bfca-79ae1049cd95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "y_pred_ptron = ptron.predict(X_test)\n",
        "report_ptron = classification_report(y_test,y_pred_ptron,  output_dict=True)\n",
        "report_ptron = pd.DataFrame(report_ptron)\n",
        "report_ptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "75d384e3-90f6-453d-9668-c20907ccc772",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d384e3-90f6-453d-9668-c20907ccc772",
        "outputId": "657ce0c6-af30-49ed-b7c6-a5f1b67fa3bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.547554347826087"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "cross = cross_val_score(ptron, X_selected, y, cv=10)\n",
        "cross.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a5f8a7a-5319-40a5-b091-d8ea07fc93e8",
      "metadata": {
        "id": "7a5f8a7a-5319-40a5-b091-d8ea07fc93e8"
      },
      "source": [
        "Linear discriminant analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "c163ce4f-767a-48b8-a4d4-f9e5c5f67ec3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "c163ce4f-767a-48b8-a4d4-f9e5c5f67ec3",
        "outputId": "a35c9eaf-eda9-4559-872f-1ef2067d8189"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearDiscriminantAnalysis()"
            ],
            "text/html": [
              "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "2a734e26-8d0e-4134-8c8e-e85c437f3f03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "2a734e26-8d0e-4134-8c8e-e85c437f3f03",
        "outputId": "c14ea4f6-6ff1-4a50-e27f-a027db72d961"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0           1  accuracy    macro avg  weighted avg\n",
              "precision    0.686200    0.676522  0.681159     0.681361      0.681335\n",
              "recall       0.661202    0.700901  0.681159     0.681052      0.681159\n",
              "f1-score     0.673469    0.688496  0.681159     0.680982      0.681023\n",
              "support    549.000000  555.000000  0.681159  1104.000000   1104.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fefda456-2170-490f-beaa-ab55c53dccc2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.686200</td>\n",
              "      <td>0.676522</td>\n",
              "      <td>0.681159</td>\n",
              "      <td>0.681361</td>\n",
              "      <td>0.681335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.661202</td>\n",
              "      <td>0.700901</td>\n",
              "      <td>0.681159</td>\n",
              "      <td>0.681052</td>\n",
              "      <td>0.681159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.673469</td>\n",
              "      <td>0.688496</td>\n",
              "      <td>0.681159</td>\n",
              "      <td>0.680982</td>\n",
              "      <td>0.681023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>555.000000</td>\n",
              "      <td>0.681159</td>\n",
              "      <td>1104.000000</td>\n",
              "      <td>1104.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fefda456-2170-490f-beaa-ab55c53dccc2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fefda456-2170-490f-beaa-ab55c53dccc2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fefda456-2170-490f-beaa-ab55c53dccc2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "y_pred_lda = lda.predict(X_test)\n",
        "report_lda = classification_report(y_test,y_pred_lda,  output_dict=True)\n",
        "report_lda = pd.DataFrame(report_lda)\n",
        "report_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "a2ed584f-b21e-4f24-ad25-e106caed419b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2ed584f-b21e-4f24-ad25-e106caed419b",
        "outputId": "7421a14f-db5d-4271-9c1d-9eb2607e962b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6478260869565218"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "cross = cross_val_score(lda, X_selected, y, cv=10)\n",
        "cross.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f82791e-1099-4c2a-be40-63ec986acf57",
      "metadata": {
        "id": "8f82791e-1099-4c2a-be40-63ec986acf57"
      },
      "source": [
        "Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "8a1f0d7d-f057-4073-a69a-bd18ff02f610",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "8a1f0d7d-f057-4073-a69a-bd18ff02f610",
        "outputId": "10c79dd9-034a-4b71-ffa4-48023c54d0f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=5)"
            ],
            "text/html": [
              "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "DT = DecisionTreeClassifier(max_depth=5)\n",
        "DT.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "755af273-cd4f-43ba-8ded-d10e26d98bdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "755af273-cd4f-43ba-8ded-d10e26d98bdf",
        "outputId": "764778d7-950e-4139-cecd-ecd503f0db32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0           1  accuracy    macro avg  weighted avg\n",
              "precision    0.621824    0.694253  0.650362     0.658038      0.658235\n",
              "recall       0.757741    0.544144  0.650362     0.650943      0.650362\n",
              "f1-score     0.683087    0.610101  0.650362     0.646594      0.646396\n",
              "support    549.000000  555.000000  0.650362  1104.000000   1104.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f505b124-2012-4bd7-8df9-21bb894ebd96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.621824</td>\n",
              "      <td>0.694253</td>\n",
              "      <td>0.650362</td>\n",
              "      <td>0.658038</td>\n",
              "      <td>0.658235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.757741</td>\n",
              "      <td>0.544144</td>\n",
              "      <td>0.650362</td>\n",
              "      <td>0.650943</td>\n",
              "      <td>0.650362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.683087</td>\n",
              "      <td>0.610101</td>\n",
              "      <td>0.650362</td>\n",
              "      <td>0.646594</td>\n",
              "      <td>0.646396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>555.000000</td>\n",
              "      <td>0.650362</td>\n",
              "      <td>1104.000000</td>\n",
              "      <td>1104.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f505b124-2012-4bd7-8df9-21bb894ebd96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f505b124-2012-4bd7-8df9-21bb894ebd96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f505b124-2012-4bd7-8df9-21bb894ebd96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "y_pred_DT = DT.predict(X_test)\n",
        "report_DT = classification_report(y_test,y_pred_DT,  output_dict=True)\n",
        "report_DT = pd.DataFrame(report_DT)\n",
        "report_DT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "06f82381-6909-41d3-8fd4-0ea18d27775c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06f82381-6909-41d3-8fd4-0ea18d27775c",
        "outputId": "02ab4ca1-acbb-462a-a282-81d0c92faf87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6304347826086956"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "cross = cross_val_score(DT, X_selected, y, cv=10)\n",
        "cross.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "989bbf94-cc92-41cc-8e91-548c25d061f2",
      "metadata": {
        "id": "989bbf94-cc92-41cc-8e91-548c25d061f2"
      },
      "source": [
        "XGboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "6cb3ffb1-8f91-4022-800d-12d4257e8c44",
      "metadata": {
        "id": "6cb3ffb1-8f91-4022-800d-12d4257e8c44"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "5bbce539-87d7-48b5-9d9a-640ff920640e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bbce539-87d7-48b5-9d9a-640ff920640e",
        "outputId": "4ab6ec4c-8a4e-4313-bae3-2bbebda94210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:17:18] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'max_depth': 3,\n",
        "    'learning_rate': 0.1,\n",
        "    'n_estimators': 100\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "xgb_model = xgb.train(params, dtrain)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "655b0e65-ea78-426b-9434-64195fdeade3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "655b0e65-ea78-426b-9434-64195fdeade3",
        "outputId": "0b0de4b7-7e50-4198-fc0a-3b75d211abd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0           1  accuracy    macro avg  weighted avg\n",
              "precision    0.658318    0.667890  0.663043     0.663104      0.663130\n",
              "recall       0.670310    0.655856  0.663043     0.663083      0.663043\n",
              "f1-score     0.664260    0.661818  0.663043     0.663039      0.663032\n",
              "support    549.000000  555.000000  0.663043  1104.000000   1104.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ee189ff-d163-4b7b-9e2e-a96ae2f97cdb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.658318</td>\n",
              "      <td>0.667890</td>\n",
              "      <td>0.663043</td>\n",
              "      <td>0.663104</td>\n",
              "      <td>0.663130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.670310</td>\n",
              "      <td>0.655856</td>\n",
              "      <td>0.663043</td>\n",
              "      <td>0.663083</td>\n",
              "      <td>0.663043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.664260</td>\n",
              "      <td>0.661818</td>\n",
              "      <td>0.663043</td>\n",
              "      <td>0.663039</td>\n",
              "      <td>0.663032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>555.000000</td>\n",
              "      <td>0.663043</td>\n",
              "      <td>1104.000000</td>\n",
              "      <td>1104.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ee189ff-d163-4b7b-9e2e-a96ae2f97cdb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ee189ff-d163-4b7b-9e2e-a96ae2f97cdb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ee189ff-d163-4b7b-9e2e-a96ae2f97cdb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "# Make predictions on the test data\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "y_pred_xgb = xgb_model.predict(dtest)\n",
        "\n",
        "# Convert the predicted probabilities to binary labels\n",
        "y_pred_xgb = (y_pred_xgb > 0.5).astype(int)\n",
        "report_xgb = classification_report(y_test,y_pred_xgb,  output_dict=True)\n",
        "report_xgb = pd.DataFrame(report_xgb)\n",
        "report_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "bbe9869d-5286-497e-b74e-81d381fbba19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "bbe9869d-5286-497e-b74e-81d381fbba19",
        "outputId": "1798c461-6f80-4260-aedf-ed5af3a2c28e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:17:19] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "[22:17:19] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "[22:17:19] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "[22:17:19] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "[22:17:19] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "[22:17:19] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "[22:17:19] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "[22:17:19] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "[22:17:19] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "[22:17:19] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   train-logloss-mean  train-logloss-std  test-logloss-mean  test-logloss-std\n",
              "0            0.679944           0.000712           0.682384          0.001893\n",
              "1            0.668496           0.001285           0.673675          0.003468\n",
              "2            0.658435           0.001779           0.665817          0.004900\n",
              "3            0.649548           0.001710           0.658685          0.005598\n",
              "4            0.642077           0.001761           0.653600          0.006484\n",
              "5            0.634989           0.001938           0.648482          0.006991\n",
              "6            0.628928           0.001977           0.643857          0.007990\n",
              "7            0.622864           0.001801           0.639561          0.009192\n",
              "8            0.617548           0.001572           0.636082          0.009900\n",
              "9            0.612425           0.001336           0.632100          0.010977"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-497ae58d-a323-4b43-ac31-c13f05e0c3f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train-logloss-mean</th>\n",
              "      <th>train-logloss-std</th>\n",
              "      <th>test-logloss-mean</th>\n",
              "      <th>test-logloss-std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.679944</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.682384</td>\n",
              "      <td>0.001893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.668496</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>0.673675</td>\n",
              "      <td>0.003468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.658435</td>\n",
              "      <td>0.001779</td>\n",
              "      <td>0.665817</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.649548</td>\n",
              "      <td>0.001710</td>\n",
              "      <td>0.658685</td>\n",
              "      <td>0.005598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.642077</td>\n",
              "      <td>0.001761</td>\n",
              "      <td>0.653600</td>\n",
              "      <td>0.006484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.634989</td>\n",
              "      <td>0.001938</td>\n",
              "      <td>0.648482</td>\n",
              "      <td>0.006991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.628928</td>\n",
              "      <td>0.001977</td>\n",
              "      <td>0.643857</td>\n",
              "      <td>0.007990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.622864</td>\n",
              "      <td>0.001801</td>\n",
              "      <td>0.639561</td>\n",
              "      <td>0.009192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.617548</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.636082</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.612425</td>\n",
              "      <td>0.001336</td>\n",
              "      <td>0.632100</td>\n",
              "      <td>0.010977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-497ae58d-a323-4b43-ac31-c13f05e0c3f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-497ae58d-a323-4b43-ac31-c13f05e0c3f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-497ae58d-a323-4b43-ac31-c13f05e0c3f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "cv_results = xgb.cv(params, dtrain, nfold=10)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "efd88484-061c-4239-8388-c04fc4907474",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efd88484-061c-4239-8388-c04fc4907474",
        "outputId": "9b16a681-79be-460c-e886-6af01a117a9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6534244046870399"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "cross_mean = cv_results['test-logloss-mean'].to_numpy().mean()\n",
        "cross_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ca062da-8725-4a8a-bcbe-3e7f6209cdcd",
      "metadata": {
        "id": "3ca062da-8725-4a8a-bcbe-3e7f6209cdcd"
      },
      "source": [
        "Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "3aae58a4-b649-4cd9-aa40-1fc7efd6ab49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "3aae58a4-b649-4cd9-aa40-1fc7efd6ab49",
        "outputId": "9867f6ff-915b-4699-d786-df04eb5f5a2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "3efe9c03-7416-4280-a147-815c16ab575f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "3efe9c03-7416-4280-a147-815c16ab575f",
        "outputId": "f1509723-1b00-417e-9a2b-26a72e4ba083"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0           1  accuracy    macro avg  weighted avg\n",
              "precision    0.682060    0.695009  0.688406     0.688535      0.688570\n",
              "recall       0.699454    0.677477  0.688406     0.688466      0.688406\n",
              "f1-score     0.690647    0.686131  0.688406     0.688389      0.688377\n",
              "support    549.000000  555.000000  0.688406  1104.000000   1104.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff68ce73-434a-4659-bcd3-17f5fb6ac166\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.682060</td>\n",
              "      <td>0.695009</td>\n",
              "      <td>0.688406</td>\n",
              "      <td>0.688535</td>\n",
              "      <td>0.688570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.699454</td>\n",
              "      <td>0.677477</td>\n",
              "      <td>0.688406</td>\n",
              "      <td>0.688466</td>\n",
              "      <td>0.688406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.690647</td>\n",
              "      <td>0.686131</td>\n",
              "      <td>0.688406</td>\n",
              "      <td>0.688389</td>\n",
              "      <td>0.688377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>555.000000</td>\n",
              "      <td>0.688406</td>\n",
              "      <td>1104.000000</td>\n",
              "      <td>1104.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff68ce73-434a-4659-bcd3-17f5fb6ac166')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff68ce73-434a-4659-bcd3-17f5fb6ac166 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff68ce73-434a-4659-bcd3-17f5fb6ac166');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "y_pred_rf = rf.predict(X_test)\n",
        "report_rf = classification_report(y_test,y_pred_rf,  output_dict=True)\n",
        "report_rf = pd.DataFrame(report_rf)\n",
        "report_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "6cbcc4e9-4e30-4d3d-b175-39944f503448",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cbcc4e9-4e30-4d3d-b175-39944f503448",
        "outputId": "1d65efb0-1a82-4d4f-9631-8bd9b84bda3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6467391304347826"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "cross = cross_val_score(rf, X_selected, y, cv=10)\n",
        "cross.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d34cf11f-3d50-4df1-81ba-bf45bf08a9bc",
      "metadata": {
        "id": "d34cf11f-3d50-4df1-81ba-bf45bf08a9bc"
      },
      "source": [
        "Support vector machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "196efdc5-b84c-4231-9e8c-7d0c349b32fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "196efdc5-b84c-4231-9e8c-7d0c349b32fd",
        "outputId": "211abe75-ec59-4a2c-f211-999686e34c27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "svm = SVC(kernel='linear', C=1)\n",
        "svm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "522bf1da-dcd8-419b-917c-712754c2c18e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "522bf1da-dcd8-419b-917c-712754c2c18e",
        "outputId": "2fb6b4c6-3e0f-44ad-fb8d-882d105c5cba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0           1  accuracy    macro avg  weighted avg\n",
              "precision    0.677778    0.675532   0.67663     0.676655      0.676649\n",
              "recall       0.666667    0.686486   0.67663     0.676577      0.676630\n",
              "f1-score     0.672176    0.680965   0.67663     0.676571      0.676595\n",
              "support    549.000000  555.000000   0.67663  1104.000000   1104.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83ef1953-8dda-46be-8e43-4c07ab4afb3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.677778</td>\n",
              "      <td>0.675532</td>\n",
              "      <td>0.67663</td>\n",
              "      <td>0.676655</td>\n",
              "      <td>0.676649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.686486</td>\n",
              "      <td>0.67663</td>\n",
              "      <td>0.676577</td>\n",
              "      <td>0.676630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.672176</td>\n",
              "      <td>0.680965</td>\n",
              "      <td>0.67663</td>\n",
              "      <td>0.676571</td>\n",
              "      <td>0.676595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>555.000000</td>\n",
              "      <td>0.67663</td>\n",
              "      <td>1104.000000</td>\n",
              "      <td>1104.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83ef1953-8dda-46be-8e43-4c07ab4afb3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83ef1953-8dda-46be-8e43-4c07ab4afb3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83ef1953-8dda-46be-8e43-4c07ab4afb3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "y_pred_svm = svm.predict(X_test)\n",
        "report_svm = classification_report(y_test,y_pred_svm, output_dict=True)\n",
        "report_svm = pd.DataFrame(report_svm)\n",
        "report_svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "60816dae-27ed-4cd6-be6a-ca94e9ce7f28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60816dae-27ed-4cd6-be6a-ca94e9ce7f28",
        "outputId": "28a8f0ff-c047-4cf7-b88c-98d9c687eb86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.646195652173913"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "cross = cross_val_score(svm, X_selected, y, cv=10)\n",
        "cross.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep neural network"
      ],
      "metadata": {
        "id": "2dcXTpZX6oxu"
      },
      "id": "2dcXTpZX6oxu"
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "eeed21fe-2465-4b47-9188-9ff042a1c98f",
      "metadata": {
        "id": "eeed21fe-2465-4b47-9188-9ff042a1c98f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "# # split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25)\n",
        "\n",
        "# split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30)\n",
        "\n",
        "# Define the model\n",
        "dnn = keras.Sequential([\n",
        "    layers.Dense(8, activation='sigmoid', input_shape=(10,)),\n",
        "    layers.Dense(8, activation='sigmoid'),\n",
        "    layers.Dense(8, activation='sigmoid'),\n",
        "    layers.Dense(6, activation='sigmoid'),\n",
        "    layers.Dense(6, activation='sigmoid'),\n",
        "    layers.Dense(6, activation='sigmoid'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "dnn.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model to the training data\n",
        "history = dnn.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1000, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36eGWit-D943",
        "outputId": "37936ef7-9ab8-4d4b-88ec-59580568f904"
      },
      "id": "36eGWit-D943",
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 5s 12ms/step - loss: 0.7016 - accuracy: 0.4997 - val_loss: 0.6930 - val_accuracy: 0.5097\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6935 - accuracy: 0.4912 - val_loss: 0.6930 - val_accuracy: 0.5097\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.6934 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5097\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 1s 11ms/step - loss: 0.6934 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5097\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 1s 13ms/step - loss: 0.6934 - accuracy: 0.4949 - val_loss: 0.6929 - val_accuracy: 0.5097\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 13ms/step - loss: 0.6933 - accuracy: 0.4961 - val_loss: 0.6932 - val_accuracy: 0.4903\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 2s 15ms/step - loss: 0.6934 - accuracy: 0.4943 - val_loss: 0.6939 - val_accuracy: 0.4903\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.4912 - val_loss: 0.6931 - val_accuracy: 0.4903\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 11ms/step - loss: 0.6935 - accuracy: 0.4819 - val_loss: 0.6931 - val_accuracy: 0.4903\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6930 - val_accuracy: 0.5097\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6930 - val_accuracy: 0.5116\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6933 - accuracy: 0.4900 - val_loss: 0.6930 - val_accuracy: 0.4922\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6928 - val_accuracy: 0.5097\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6929 - accuracy: 0.5236 - val_loss: 0.6926 - val_accuracy: 0.5252\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6929 - accuracy: 0.5208 - val_loss: 0.6925 - val_accuracy: 0.6512\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6924 - accuracy: 0.5543 - val_loss: 0.6921 - val_accuracy: 0.6434\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6920 - accuracy: 0.5248 - val_loss: 0.6920 - val_accuracy: 0.4903\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.5664 - val_loss: 0.6902 - val_accuracy: 0.6415\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6895 - accuracy: 0.5930 - val_loss: 0.6878 - val_accuracy: 0.6376\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6864 - accuracy: 0.6168 - val_loss: 0.6840 - val_accuracy: 0.6473\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6813 - accuracy: 0.6332 - val_loss: 0.6769 - val_accuracy: 0.6453\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6712 - accuracy: 0.6353 - val_loss: 0.6667 - val_accuracy: 0.6357\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6608 - accuracy: 0.6395 - val_loss: 0.6519 - val_accuracy: 0.6531\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6466 - accuracy: 0.6537 - val_loss: 0.6386 - val_accuracy: 0.6415\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6363 - accuracy: 0.6561 - val_loss: 0.6314 - val_accuracy: 0.6531\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6289 - accuracy: 0.6588 - val_loss: 0.6233 - val_accuracy: 0.6357\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6243 - accuracy: 0.6570 - val_loss: 0.6209 - val_accuracy: 0.6531\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6220 - accuracy: 0.6570 - val_loss: 0.6168 - val_accuracy: 0.6415\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6192 - accuracy: 0.6588 - val_loss: 0.6159 - val_accuracy: 0.6376\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6182 - accuracy: 0.6627 - val_loss: 0.6134 - val_accuracy: 0.6395\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.6603 - val_loss: 0.6126 - val_accuracy: 0.6434\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6594 - val_loss: 0.6112 - val_accuracy: 0.6492\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6163 - accuracy: 0.6627 - val_loss: 0.6104 - val_accuracy: 0.6434\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.6594 - val_loss: 0.6095 - val_accuracy: 0.6492\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6146 - accuracy: 0.6600 - val_loss: 0.6130 - val_accuracy: 0.6512\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6148 - accuracy: 0.6643 - val_loss: 0.6105 - val_accuracy: 0.6570\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6134 - accuracy: 0.6615 - val_loss: 0.6110 - val_accuracy: 0.6550\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6131 - accuracy: 0.6652 - val_loss: 0.6071 - val_accuracy: 0.6473\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6135 - accuracy: 0.6667 - val_loss: 0.6065 - val_accuracy: 0.6589\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6134 - accuracy: 0.6652 - val_loss: 0.6075 - val_accuracy: 0.6531\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6123 - accuracy: 0.6636 - val_loss: 0.6060 - val_accuracy: 0.6609\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6120 - accuracy: 0.6612 - val_loss: 0.6051 - val_accuracy: 0.6570\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6116 - accuracy: 0.6609 - val_loss: 0.6046 - val_accuracy: 0.6512\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6113 - accuracy: 0.6664 - val_loss: 0.6058 - val_accuracy: 0.6609\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6110 - accuracy: 0.6673 - val_loss: 0.6038 - val_accuracy: 0.6512\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6114 - accuracy: 0.6633 - val_loss: 0.6035 - val_accuracy: 0.6647\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6107 - accuracy: 0.6639 - val_loss: 0.6031 - val_accuracy: 0.6628\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6113 - accuracy: 0.6612 - val_loss: 0.6027 - val_accuracy: 0.6647\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6100 - accuracy: 0.6627 - val_loss: 0.6034 - val_accuracy: 0.6667\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6095 - accuracy: 0.6673 - val_loss: 0.6022 - val_accuracy: 0.6647\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6102 - accuracy: 0.6630 - val_loss: 0.6018 - val_accuracy: 0.6609\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6096 - accuracy: 0.6636 - val_loss: 0.6011 - val_accuracy: 0.6570\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6098 - accuracy: 0.6643 - val_loss: 0.6013 - val_accuracy: 0.6647\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6092 - accuracy: 0.6636 - val_loss: 0.6004 - val_accuracy: 0.6589\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6086 - accuracy: 0.6639 - val_loss: 0.6009 - val_accuracy: 0.6686\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6085 - accuracy: 0.6661 - val_loss: 0.6001 - val_accuracy: 0.6686\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6086 - accuracy: 0.6655 - val_loss: 0.5996 - val_accuracy: 0.6647\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6081 - accuracy: 0.6685 - val_loss: 0.5992 - val_accuracy: 0.6609\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6082 - accuracy: 0.6630 - val_loss: 0.5991 - val_accuracy: 0.6667\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6077 - accuracy: 0.6615 - val_loss: 0.5989 - val_accuracy: 0.6667\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6078 - accuracy: 0.6694 - val_loss: 0.5989 - val_accuracy: 0.6628\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6071 - accuracy: 0.6652 - val_loss: 0.5999 - val_accuracy: 0.6667\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6071 - accuracy: 0.6646 - val_loss: 0.5987 - val_accuracy: 0.6744\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6073 - accuracy: 0.6655 - val_loss: 0.5990 - val_accuracy: 0.6705\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6076 - accuracy: 0.6667 - val_loss: 0.5975 - val_accuracy: 0.6667\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6068 - accuracy: 0.6691 - val_loss: 0.5994 - val_accuracy: 0.6550\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6069 - accuracy: 0.6667 - val_loss: 0.5968 - val_accuracy: 0.6705\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6069 - accuracy: 0.6682 - val_loss: 0.5966 - val_accuracy: 0.6705\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6065 - accuracy: 0.6661 - val_loss: 0.5971 - val_accuracy: 0.6628\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6059 - accuracy: 0.6661 - val_loss: 0.5961 - val_accuracy: 0.6667\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6066 - accuracy: 0.6633 - val_loss: 0.5959 - val_accuracy: 0.6705\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6061 - accuracy: 0.6649 - val_loss: 0.5997 - val_accuracy: 0.6667\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6058 - accuracy: 0.6670 - val_loss: 0.5955 - val_accuracy: 0.6725\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6054 - accuracy: 0.6697 - val_loss: 0.5956 - val_accuracy: 0.6667\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6051 - accuracy: 0.6661 - val_loss: 0.5968 - val_accuracy: 0.6686\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6055 - accuracy: 0.6685 - val_loss: 0.5948 - val_accuracy: 0.6725\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6054 - accuracy: 0.6685 - val_loss: 0.5952 - val_accuracy: 0.6628\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6055 - accuracy: 0.6703 - val_loss: 0.5947 - val_accuracy: 0.6628\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6052 - accuracy: 0.6633 - val_loss: 0.5943 - val_accuracy: 0.6764\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6048 - accuracy: 0.6703 - val_loss: 0.5955 - val_accuracy: 0.6705\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6040 - accuracy: 0.6703 - val_loss: 0.5964 - val_accuracy: 0.6705\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6050 - accuracy: 0.6694 - val_loss: 0.5941 - val_accuracy: 0.6764\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6043 - accuracy: 0.6718 - val_loss: 0.5936 - val_accuracy: 0.6764\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6047 - accuracy: 0.6703 - val_loss: 0.5950 - val_accuracy: 0.6531\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6050 - accuracy: 0.6643 - val_loss: 0.5935 - val_accuracy: 0.6783\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6038 - accuracy: 0.6679 - val_loss: 0.5942 - val_accuracy: 0.6512\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6039 - accuracy: 0.6682 - val_loss: 0.5936 - val_accuracy: 0.6725\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6043 - accuracy: 0.6691 - val_loss: 0.5929 - val_accuracy: 0.6667\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.6039 - accuracy: 0.6682 - val_loss: 0.5927 - val_accuracy: 0.6783\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6040 - accuracy: 0.6706 - val_loss: 0.5923 - val_accuracy: 0.6783\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6032 - accuracy: 0.6715 - val_loss: 0.5926 - val_accuracy: 0.6628\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6037 - accuracy: 0.6706 - val_loss: 0.5923 - val_accuracy: 0.6783\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6031 - accuracy: 0.6733 - val_loss: 0.5929 - val_accuracy: 0.6744\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6032 - accuracy: 0.6730 - val_loss: 0.5919 - val_accuracy: 0.6822\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6035 - accuracy: 0.6721 - val_loss: 0.5918 - val_accuracy: 0.6764\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6036 - accuracy: 0.6700 - val_loss: 0.5921 - val_accuracy: 0.6783\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6032 - accuracy: 0.6709 - val_loss: 0.5916 - val_accuracy: 0.6686\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6033 - accuracy: 0.6697 - val_loss: 0.5917 - val_accuracy: 0.6647\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6027 - accuracy: 0.6727 - val_loss: 0.5913 - val_accuracy: 0.6802\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6026 - accuracy: 0.6730 - val_loss: 0.5910 - val_accuracy: 0.6822\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6030 - accuracy: 0.6706 - val_loss: 0.5909 - val_accuracy: 0.6822\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6028 - accuracy: 0.6730 - val_loss: 0.5909 - val_accuracy: 0.6725\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6013 - accuracy: 0.6697 - val_loss: 0.5925 - val_accuracy: 0.6841\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6025 - accuracy: 0.6745 - val_loss: 0.5923 - val_accuracy: 0.6841\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6024 - accuracy: 0.6715 - val_loss: 0.5903 - val_accuracy: 0.6822\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6023 - accuracy: 0.6733 - val_loss: 0.5902 - val_accuracy: 0.6841\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6023 - accuracy: 0.6721 - val_loss: 0.5903 - val_accuracy: 0.6802\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6027 - accuracy: 0.6673 - val_loss: 0.5903 - val_accuracy: 0.6822\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6025 - accuracy: 0.6754 - val_loss: 0.5901 - val_accuracy: 0.6744\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6020 - accuracy: 0.6682 - val_loss: 0.5926 - val_accuracy: 0.6531\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6030 - accuracy: 0.6679 - val_loss: 0.5902 - val_accuracy: 0.6647\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6023 - accuracy: 0.6718 - val_loss: 0.5896 - val_accuracy: 0.6841\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6015 - accuracy: 0.6724 - val_loss: 0.5897 - val_accuracy: 0.6841\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6022 - accuracy: 0.6697 - val_loss: 0.5897 - val_accuracy: 0.6783\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6022 - accuracy: 0.6730 - val_loss: 0.5917 - val_accuracy: 0.6802\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6021 - accuracy: 0.6700 - val_loss: 0.5891 - val_accuracy: 0.6841\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6014 - accuracy: 0.6730 - val_loss: 0.5891 - val_accuracy: 0.6802\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6021 - accuracy: 0.6751 - val_loss: 0.5891 - val_accuracy: 0.6860\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6019 - accuracy: 0.6724 - val_loss: 0.5892 - val_accuracy: 0.6667\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6017 - accuracy: 0.6688 - val_loss: 0.5893 - val_accuracy: 0.6822\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6010 - accuracy: 0.6742 - val_loss: 0.5890 - val_accuracy: 0.6686\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6027 - accuracy: 0.6718 - val_loss: 0.5886 - val_accuracy: 0.6802\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6012 - accuracy: 0.6712 - val_loss: 0.5893 - val_accuracy: 0.6841\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6010 - accuracy: 0.6727 - val_loss: 0.5883 - val_accuracy: 0.6802\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6011 - accuracy: 0.6745 - val_loss: 0.5887 - val_accuracy: 0.6841\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6026 - accuracy: 0.6739 - val_loss: 0.5881 - val_accuracy: 0.6822\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6028 - accuracy: 0.6736 - val_loss: 0.5882 - val_accuracy: 0.6860\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6008 - accuracy: 0.6724 - val_loss: 0.5881 - val_accuracy: 0.6860\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6010 - accuracy: 0.6760 - val_loss: 0.5896 - val_accuracy: 0.6860\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6013 - accuracy: 0.6763 - val_loss: 0.5879 - val_accuracy: 0.6899\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6007 - accuracy: 0.6742 - val_loss: 0.5879 - val_accuracy: 0.6764\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6005 - accuracy: 0.6736 - val_loss: 0.5877 - val_accuracy: 0.6802\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6013 - accuracy: 0.6751 - val_loss: 0.5877 - val_accuracy: 0.6783\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6009 - accuracy: 0.6745 - val_loss: 0.5884 - val_accuracy: 0.6822\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6004 - accuracy: 0.6730 - val_loss: 0.5881 - val_accuracy: 0.6860\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6008 - accuracy: 0.6778 - val_loss: 0.5876 - val_accuracy: 0.6880\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6007 - accuracy: 0.6745 - val_loss: 0.5877 - val_accuracy: 0.6919\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5999 - accuracy: 0.6742 - val_loss: 0.5912 - val_accuracy: 0.6822\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6011 - accuracy: 0.6685 - val_loss: 0.5901 - val_accuracy: 0.6841\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6006 - accuracy: 0.6766 - val_loss: 0.5885 - val_accuracy: 0.6841\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6017 - accuracy: 0.6757 - val_loss: 0.5877 - val_accuracy: 0.6919\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6006 - accuracy: 0.6772 - val_loss: 0.5870 - val_accuracy: 0.6802\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6000 - accuracy: 0.6766 - val_loss: 0.5876 - val_accuracy: 0.6919\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6002 - accuracy: 0.6754 - val_loss: 0.5897 - val_accuracy: 0.6880\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6009 - accuracy: 0.6751 - val_loss: 0.5872 - val_accuracy: 0.6744\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6011 - accuracy: 0.6733 - val_loss: 0.5866 - val_accuracy: 0.6841\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6003 - accuracy: 0.6781 - val_loss: 0.5893 - val_accuracy: 0.6880\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6008 - accuracy: 0.6748 - val_loss: 0.5867 - val_accuracy: 0.6822\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5998 - accuracy: 0.6709 - val_loss: 0.5867 - val_accuracy: 0.6899\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6011 - accuracy: 0.6748 - val_loss: 0.5865 - val_accuracy: 0.6860\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5999 - accuracy: 0.6706 - val_loss: 0.5867 - val_accuracy: 0.6744\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6000 - accuracy: 0.6739 - val_loss: 0.5862 - val_accuracy: 0.6899\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6002 - accuracy: 0.6754 - val_loss: 0.5864 - val_accuracy: 0.6899\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5998 - accuracy: 0.6763 - val_loss: 0.5862 - val_accuracy: 0.6860\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5999 - accuracy: 0.6739 - val_loss: 0.5862 - val_accuracy: 0.6841\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6006 - accuracy: 0.6739 - val_loss: 0.5865 - val_accuracy: 0.6686\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6001 - accuracy: 0.6715 - val_loss: 0.5859 - val_accuracy: 0.6899\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6006 - accuracy: 0.6736 - val_loss: 0.5864 - val_accuracy: 0.6880\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5996 - accuracy: 0.6739 - val_loss: 0.5870 - val_accuracy: 0.6860\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5995 - accuracy: 0.6796 - val_loss: 0.5859 - val_accuracy: 0.6822\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6001 - accuracy: 0.6742 - val_loss: 0.5857 - val_accuracy: 0.6919\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5998 - accuracy: 0.6718 - val_loss: 0.5859 - val_accuracy: 0.6899\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5999 - accuracy: 0.6688 - val_loss: 0.5862 - val_accuracy: 0.6667\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5998 - accuracy: 0.6739 - val_loss: 0.5859 - val_accuracy: 0.6783\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5996 - accuracy: 0.6775 - val_loss: 0.5857 - val_accuracy: 0.6899\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5994 - accuracy: 0.6754 - val_loss: 0.5857 - val_accuracy: 0.6860\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6010 - accuracy: 0.6742 - val_loss: 0.5860 - val_accuracy: 0.6880\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5997 - accuracy: 0.6760 - val_loss: 0.5859 - val_accuracy: 0.6880\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5999 - accuracy: 0.6742 - val_loss: 0.5856 - val_accuracy: 0.6764\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6003 - accuracy: 0.6772 - val_loss: 0.5855 - val_accuracy: 0.6938\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5990 - accuracy: 0.6700 - val_loss: 0.5894 - val_accuracy: 0.6822\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5996 - accuracy: 0.6763 - val_loss: 0.5855 - val_accuracy: 0.6860\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5993 - accuracy: 0.6760 - val_loss: 0.5852 - val_accuracy: 0.6919\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6005 - accuracy: 0.6787 - val_loss: 0.5862 - val_accuracy: 0.6647\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5993 - accuracy: 0.6733 - val_loss: 0.5855 - val_accuracy: 0.6725\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5996 - accuracy: 0.6727 - val_loss: 0.5851 - val_accuracy: 0.6919\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5998 - accuracy: 0.6694 - val_loss: 0.5852 - val_accuracy: 0.6919\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5997 - accuracy: 0.6754 - val_loss: 0.5852 - val_accuracy: 0.6919\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5988 - accuracy: 0.6754 - val_loss: 0.5864 - val_accuracy: 0.6899\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6000 - accuracy: 0.6676 - val_loss: 0.5857 - val_accuracy: 0.6860\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5992 - accuracy: 0.6760 - val_loss: 0.5854 - val_accuracy: 0.6860\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5992 - accuracy: 0.6766 - val_loss: 0.5849 - val_accuracy: 0.6899\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6001 - accuracy: 0.6730 - val_loss: 0.5861 - val_accuracy: 0.6647\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5995 - accuracy: 0.6754 - val_loss: 0.5853 - val_accuracy: 0.6860\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5998 - accuracy: 0.6715 - val_loss: 0.5872 - val_accuracy: 0.6899\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5989 - accuracy: 0.6730 - val_loss: 0.5853 - val_accuracy: 0.6880\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6000 - accuracy: 0.6700 - val_loss: 0.5850 - val_accuracy: 0.6899\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5998 - accuracy: 0.6751 - val_loss: 0.5858 - val_accuracy: 0.6686\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5992 - accuracy: 0.6751 - val_loss: 0.5847 - val_accuracy: 0.6919\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5990 - accuracy: 0.6769 - val_loss: 0.5845 - val_accuracy: 0.6938\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5990 - accuracy: 0.6721 - val_loss: 0.5847 - val_accuracy: 0.6899\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5995 - accuracy: 0.6733 - val_loss: 0.5846 - val_accuracy: 0.6919\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5994 - accuracy: 0.6766 - val_loss: 0.5850 - val_accuracy: 0.6880\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5985 - accuracy: 0.6757 - val_loss: 0.5866 - val_accuracy: 0.6628\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5994 - accuracy: 0.6703 - val_loss: 0.5848 - val_accuracy: 0.6860\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5987 - accuracy: 0.6757 - val_loss: 0.5846 - val_accuracy: 0.6860\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5990 - accuracy: 0.6766 - val_loss: 0.5851 - val_accuracy: 0.6686\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5991 - accuracy: 0.6778 - val_loss: 0.5845 - val_accuracy: 0.6860\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5991 - accuracy: 0.6739 - val_loss: 0.5842 - val_accuracy: 0.6957\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5987 - accuracy: 0.6781 - val_loss: 0.5842 - val_accuracy: 0.6938\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5986 - accuracy: 0.6760 - val_loss: 0.5841 - val_accuracy: 0.6880\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5989 - accuracy: 0.6754 - val_loss: 0.5843 - val_accuracy: 0.6938\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5983 - accuracy: 0.6766 - val_loss: 0.5844 - val_accuracy: 0.6802\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5983 - accuracy: 0.6809 - val_loss: 0.5846 - val_accuracy: 0.6802\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5987 - accuracy: 0.6763 - val_loss: 0.5841 - val_accuracy: 0.6938\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5986 - accuracy: 0.6815 - val_loss: 0.5840 - val_accuracy: 0.6957\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5982 - accuracy: 0.6760 - val_loss: 0.5850 - val_accuracy: 0.6919\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5992 - accuracy: 0.6751 - val_loss: 0.5841 - val_accuracy: 0.6919\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5988 - accuracy: 0.6754 - val_loss: 0.5844 - val_accuracy: 0.6802\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5989 - accuracy: 0.6736 - val_loss: 0.5842 - val_accuracy: 0.6938\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5982 - accuracy: 0.6769 - val_loss: 0.5856 - val_accuracy: 0.6647\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5982 - accuracy: 0.6736 - val_loss: 0.5840 - val_accuracy: 0.6802\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5988 - accuracy: 0.6739 - val_loss: 0.5845 - val_accuracy: 0.6899\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5985 - accuracy: 0.6763 - val_loss: 0.5840 - val_accuracy: 0.6802\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5989 - accuracy: 0.6769 - val_loss: 0.5840 - val_accuracy: 0.6802\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5982 - accuracy: 0.6757 - val_loss: 0.5840 - val_accuracy: 0.6783\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5991 - accuracy: 0.6769 - val_loss: 0.5839 - val_accuracy: 0.6880\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5995 - accuracy: 0.6772 - val_loss: 0.5841 - val_accuracy: 0.6802\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5982 - accuracy: 0.6763 - val_loss: 0.5839 - val_accuracy: 0.6938\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5979 - accuracy: 0.6793 - val_loss: 0.5837 - val_accuracy: 0.6899\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5981 - accuracy: 0.6766 - val_loss: 0.5842 - val_accuracy: 0.6919\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5983 - accuracy: 0.6781 - val_loss: 0.5841 - val_accuracy: 0.6802\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5987 - accuracy: 0.6769 - val_loss: 0.5841 - val_accuracy: 0.6938\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5983 - accuracy: 0.6778 - val_loss: 0.5838 - val_accuracy: 0.6802\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5978 - accuracy: 0.6760 - val_loss: 0.5842 - val_accuracy: 0.6880\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5984 - accuracy: 0.6742 - val_loss: 0.5837 - val_accuracy: 0.6899\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5987 - accuracy: 0.6800 - val_loss: 0.5837 - val_accuracy: 0.6899\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5982 - accuracy: 0.6730 - val_loss: 0.5840 - val_accuracy: 0.6938\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5989 - accuracy: 0.6751 - val_loss: 0.5839 - val_accuracy: 0.6938\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5984 - accuracy: 0.6715 - val_loss: 0.5842 - val_accuracy: 0.6899\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5979 - accuracy: 0.6784 - val_loss: 0.5838 - val_accuracy: 0.6938\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5981 - accuracy: 0.6754 - val_loss: 0.5840 - val_accuracy: 0.6899\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5978 - accuracy: 0.6769 - val_loss: 0.5835 - val_accuracy: 0.6860\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5983 - accuracy: 0.6781 - val_loss: 0.5860 - val_accuracy: 0.6899\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5980 - accuracy: 0.6763 - val_loss: 0.5851 - val_accuracy: 0.6957\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5982 - accuracy: 0.6760 - val_loss: 0.5841 - val_accuracy: 0.6899\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5983 - accuracy: 0.6803 - val_loss: 0.5835 - val_accuracy: 0.6841\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5975 - accuracy: 0.6751 - val_loss: 0.5863 - val_accuracy: 0.6609\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5989 - accuracy: 0.6757 - val_loss: 0.5836 - val_accuracy: 0.6822\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5982 - accuracy: 0.6760 - val_loss: 0.5849 - val_accuracy: 0.6977\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5979 - accuracy: 0.6772 - val_loss: 0.5838 - val_accuracy: 0.6802\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5984 - accuracy: 0.6778 - val_loss: 0.5841 - val_accuracy: 0.6783\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5979 - accuracy: 0.6757 - val_loss: 0.5833 - val_accuracy: 0.6880\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5980 - accuracy: 0.6733 - val_loss: 0.5835 - val_accuracy: 0.6783\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5979 - accuracy: 0.6733 - val_loss: 0.5841 - val_accuracy: 0.6802\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5976 - accuracy: 0.6781 - val_loss: 0.5840 - val_accuracy: 0.6764\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5976 - accuracy: 0.6745 - val_loss: 0.5835 - val_accuracy: 0.6938\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5975 - accuracy: 0.6796 - val_loss: 0.5854 - val_accuracy: 0.6899\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5984 - accuracy: 0.6751 - val_loss: 0.5853 - val_accuracy: 0.6880\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5981 - accuracy: 0.6778 - val_loss: 0.5835 - val_accuracy: 0.6802\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5976 - accuracy: 0.6775 - val_loss: 0.5833 - val_accuracy: 0.6938\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5980 - accuracy: 0.6778 - val_loss: 0.5832 - val_accuracy: 0.6899\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5978 - accuracy: 0.6766 - val_loss: 0.5833 - val_accuracy: 0.6938\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5978 - accuracy: 0.6751 - val_loss: 0.5845 - val_accuracy: 0.6725\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5977 - accuracy: 0.6733 - val_loss: 0.5833 - val_accuracy: 0.6957\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5974 - accuracy: 0.6778 - val_loss: 0.5832 - val_accuracy: 0.6822\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5975 - accuracy: 0.6742 - val_loss: 0.5837 - val_accuracy: 0.6919\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5978 - accuracy: 0.6730 - val_loss: 0.5836 - val_accuracy: 0.6919\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5976 - accuracy: 0.6772 - val_loss: 0.5833 - val_accuracy: 0.6802\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5976 - accuracy: 0.6733 - val_loss: 0.5836 - val_accuracy: 0.6919\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5979 - accuracy: 0.6760 - val_loss: 0.5849 - val_accuracy: 0.6957\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5980 - accuracy: 0.6836 - val_loss: 0.5832 - val_accuracy: 0.6938\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5977 - accuracy: 0.6772 - val_loss: 0.5835 - val_accuracy: 0.6919\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5983 - accuracy: 0.6824 - val_loss: 0.5832 - val_accuracy: 0.6957\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5981 - accuracy: 0.6709 - val_loss: 0.5836 - val_accuracy: 0.6802\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5969 - accuracy: 0.6812 - val_loss: 0.5890 - val_accuracy: 0.6686\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5979 - accuracy: 0.6769 - val_loss: 0.5834 - val_accuracy: 0.6938\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5974 - accuracy: 0.6760 - val_loss: 0.5831 - val_accuracy: 0.6957\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5973 - accuracy: 0.6787 - val_loss: 0.5839 - val_accuracy: 0.6919\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5973 - accuracy: 0.6793 - val_loss: 0.5843 - val_accuracy: 0.6783\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5971 - accuracy: 0.6751 - val_loss: 0.5832 - val_accuracy: 0.6957\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5971 - accuracy: 0.6821 - val_loss: 0.5832 - val_accuracy: 0.6919\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5976 - accuracy: 0.6739 - val_loss: 0.5831 - val_accuracy: 0.6899\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5980 - accuracy: 0.6806 - val_loss: 0.5832 - val_accuracy: 0.6938\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5970 - accuracy: 0.6757 - val_loss: 0.5833 - val_accuracy: 0.6919\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5976 - accuracy: 0.6751 - val_loss: 0.5830 - val_accuracy: 0.6899\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5974 - accuracy: 0.6784 - val_loss: 0.5832 - val_accuracy: 0.6919\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5971 - accuracy: 0.6700 - val_loss: 0.5831 - val_accuracy: 0.6919\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5970 - accuracy: 0.6787 - val_loss: 0.5838 - val_accuracy: 0.6783\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5973 - accuracy: 0.6757 - val_loss: 0.5830 - val_accuracy: 0.6822\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5978 - accuracy: 0.6718 - val_loss: 0.5835 - val_accuracy: 0.6802\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5974 - accuracy: 0.6733 - val_loss: 0.5833 - val_accuracy: 0.6841\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5970 - accuracy: 0.6733 - val_loss: 0.5840 - val_accuracy: 0.6938\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5969 - accuracy: 0.6742 - val_loss: 0.5838 - val_accuracy: 0.6938\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5970 - accuracy: 0.6793 - val_loss: 0.5834 - val_accuracy: 0.6938\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5983 - accuracy: 0.6712 - val_loss: 0.5857 - val_accuracy: 0.6938\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5975 - accuracy: 0.6760 - val_loss: 0.5841 - val_accuracy: 0.6705\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5964 - accuracy: 0.6775 - val_loss: 0.5845 - val_accuracy: 0.6919\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5972 - accuracy: 0.6787 - val_loss: 0.5829 - val_accuracy: 0.6899\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5971 - accuracy: 0.6760 - val_loss: 0.5831 - val_accuracy: 0.6919\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5970 - accuracy: 0.6769 - val_loss: 0.5837 - val_accuracy: 0.6938\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5972 - accuracy: 0.6784 - val_loss: 0.5837 - val_accuracy: 0.6938\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5972 - accuracy: 0.6754 - val_loss: 0.5831 - val_accuracy: 0.6822\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5969 - accuracy: 0.6739 - val_loss: 0.5832 - val_accuracy: 0.6919\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5967 - accuracy: 0.6766 - val_loss: 0.5834 - val_accuracy: 0.6919\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5970 - accuracy: 0.6790 - val_loss: 0.5831 - val_accuracy: 0.6919\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5969 - accuracy: 0.6754 - val_loss: 0.5831 - val_accuracy: 0.6919\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5971 - accuracy: 0.6778 - val_loss: 0.5829 - val_accuracy: 0.6919\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5969 - accuracy: 0.6772 - val_loss: 0.5890 - val_accuracy: 0.6783\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5964 - accuracy: 0.6815 - val_loss: 0.5845 - val_accuracy: 0.6725\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5974 - accuracy: 0.6778 - val_loss: 0.5843 - val_accuracy: 0.6938\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5970 - accuracy: 0.6742 - val_loss: 0.5830 - val_accuracy: 0.6899\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5962 - accuracy: 0.6818 - val_loss: 0.5851 - val_accuracy: 0.6899\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5966 - accuracy: 0.6748 - val_loss: 0.5830 - val_accuracy: 0.6899\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5966 - accuracy: 0.6778 - val_loss: 0.5830 - val_accuracy: 0.6899\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5967 - accuracy: 0.6748 - val_loss: 0.5829 - val_accuracy: 0.6919\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5972 - accuracy: 0.6781 - val_loss: 0.5828 - val_accuracy: 0.6957\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5967 - accuracy: 0.6751 - val_loss: 0.5832 - val_accuracy: 0.6938\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5963 - accuracy: 0.6818 - val_loss: 0.5829 - val_accuracy: 0.6899\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5966 - accuracy: 0.6748 - val_loss: 0.5840 - val_accuracy: 0.6705\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5963 - accuracy: 0.6803 - val_loss: 0.5829 - val_accuracy: 0.6899\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5969 - accuracy: 0.6787 - val_loss: 0.5831 - val_accuracy: 0.6938\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5972 - accuracy: 0.6754 - val_loss: 0.5829 - val_accuracy: 0.6919\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5959 - accuracy: 0.6778 - val_loss: 0.5831 - val_accuracy: 0.6899\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5966 - accuracy: 0.6757 - val_loss: 0.5896 - val_accuracy: 0.6783\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5975 - accuracy: 0.6821 - val_loss: 0.5830 - val_accuracy: 0.6919\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5962 - accuracy: 0.6781 - val_loss: 0.5832 - val_accuracy: 0.6919\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5965 - accuracy: 0.6775 - val_loss: 0.5837 - val_accuracy: 0.6919\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5959 - accuracy: 0.6778 - val_loss: 0.5834 - val_accuracy: 0.6783\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5963 - accuracy: 0.6730 - val_loss: 0.5836 - val_accuracy: 0.6919\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5962 - accuracy: 0.6763 - val_loss: 0.5840 - val_accuracy: 0.6938\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5963 - accuracy: 0.6757 - val_loss: 0.5859 - val_accuracy: 0.6667\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5966 - accuracy: 0.6787 - val_loss: 0.5829 - val_accuracy: 0.6919\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5963 - accuracy: 0.6790 - val_loss: 0.5838 - val_accuracy: 0.6938\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5966 - accuracy: 0.6778 - val_loss: 0.5847 - val_accuracy: 0.6880\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5957 - accuracy: 0.6796 - val_loss: 0.5830 - val_accuracy: 0.6938\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.5961 - accuracy: 0.6754 - val_loss: 0.5856 - val_accuracy: 0.6686\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5964 - accuracy: 0.6757 - val_loss: 0.5856 - val_accuracy: 0.6880\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 0.5965 - accuracy: 0.6766 - val_loss: 0.5839 - val_accuracy: 0.6725\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 0.5964 - accuracy: 0.6812 - val_loss: 0.5831 - val_accuracy: 0.6919\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5963 - accuracy: 0.6736 - val_loss: 0.5839 - val_accuracy: 0.6938\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5968 - accuracy: 0.6748 - val_loss: 0.5836 - val_accuracy: 0.6899\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5956 - accuracy: 0.6778 - val_loss: 0.5831 - val_accuracy: 0.6938\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5961 - accuracy: 0.6803 - val_loss: 0.5836 - val_accuracy: 0.6783\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5954 - accuracy: 0.6787 - val_loss: 0.5843 - val_accuracy: 0.6860\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5955 - accuracy: 0.6812 - val_loss: 0.5890 - val_accuracy: 0.6841\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.5972 - accuracy: 0.6760 - val_loss: 0.5830 - val_accuracy: 0.6919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = dnn.evaluate(X_test, y_test)\n",
        "test_loss, test_acc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHmdl2ax6ZcB",
        "outputId": "11937322-517c-47ce-f224-2dff123f9c43"
      },
      "id": "iHmdl2ax6ZcB",
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.6766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6002169847488403, 0.676630437374115)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "ave_accuracy_dnn = []\n",
        "for train_index, test_index in kfold.split(X_selected):\n",
        "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    dnn.fit(X_train, y_train, epochs=10)\n",
        "    loss, acc = dnn.evaluate(X_test, y_test)\n",
        "    ave_accuracy_dnn.append(acc)\n",
        "    print(f'Loss: {loss}', f'accuracy: {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQE8wxO-jxo_",
        "outputId": "52b851a2-16a9-4e61-e04d-cf6e18be93ca"
      },
      "id": "OQE8wxO-jxo_",
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5957 - accuracy: 0.6748\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5957 - accuracy: 0.6775\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5955 - accuracy: 0.6724\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.6736\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5962 - accuracy: 0.6806\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.6748\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.6745\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.6787\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.6760\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6766\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6793\n",
            "Loss: 0.5998374223709106 accuracy: 0.679347813129425\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.6793\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6824\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.6827\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.6787\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.6745\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.6800\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.6778\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6839\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.6848\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.6815\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.6440\n",
            "Loss: 0.6321460008621216 accuracy: 0.64402174949646\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5977 - accuracy: 0.6724\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5980 - accuracy: 0.6733\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5986 - accuracy: 0.6712\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5989 - accuracy: 0.6682\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5979 - accuracy: 0.6775\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5979 - accuracy: 0.6730\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5977 - accuracy: 0.6748\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6787\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.6769\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.6703\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7147\n",
            "Loss: 0.572843611240387 accuracy: 0.7146739363670349\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.6766\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.6769\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6736\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.6815\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5943 - accuracy: 0.6733\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5947 - accuracy: 0.6766\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.6803\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5957 - accuracy: 0.6721\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6760\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.6824\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.6902\n",
            "Loss: 0.5974303483963013 accuracy: 0.6902173757553101\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.6790\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5967 - accuracy: 0.6806\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5961 - accuracy: 0.6691\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5966 - accuracy: 0.6775\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5961 - accuracy: 0.6781\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5967 - accuracy: 0.6706\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5965 - accuracy: 0.6787\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5966 - accuracy: 0.6760\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5960 - accuracy: 0.6766\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5960 - accuracy: 0.6766\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.6739\n",
            "Loss: 0.5758434534072876 accuracy: 0.6739130616188049\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.6757\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.6727\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5964 - accuracy: 0.6712\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5969 - accuracy: 0.6712\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5953 - accuracy: 0.6760\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.6718\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.6787\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.6739\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.6748\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.6748\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7038\n",
            "Loss: 0.5737417340278625 accuracy: 0.7038043737411499\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.6827\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5930 - accuracy: 0.6766\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5925 - accuracy: 0.6815\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5921 - accuracy: 0.6775\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5929 - accuracy: 0.6787\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5921 - accuracy: 0.6800\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.6760\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.6800\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5917 - accuracy: 0.6760\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5921 - accuracy: 0.6760\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.6739\n",
            "Loss: 0.5981640815734863 accuracy: 0.6739130616188049\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.6796\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6763\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5932 - accuracy: 0.6815\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.6748\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.6751\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5925 - accuracy: 0.6766\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5917 - accuracy: 0.6815\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5926 - accuracy: 0.6754\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5919 - accuracy: 0.6778\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5912 - accuracy: 0.6815\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.6739\n",
            "Loss: 0.5964168310165405 accuracy: 0.6739130616188049\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.6812\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5901 - accuracy: 0.6772\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5899 - accuracy: 0.6772\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.6751\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.6757\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5893 - accuracy: 0.6796\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.6796\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5885 - accuracy: 0.6800\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.6778\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5900 - accuracy: 0.6763\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6603\n",
            "Loss: 0.6095842123031616 accuracy: 0.6603260636329651\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.6781\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5926 - accuracy: 0.6787\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5931 - accuracy: 0.6724\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5927 - accuracy: 0.6778\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5926 - accuracy: 0.6803\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5929 - accuracy: 0.6718\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5927 - accuracy: 0.6781\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.6742\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5929 - accuracy: 0.6718\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.6793\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6875\n",
            "Loss: 0.5765360593795776 accuracy: 0.6875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "print(ave_accuracy_dnn, '\\n', mean(ave_accuracy_dnn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhUe7p_4x9Vb",
        "outputId": "00850ada-38a3-49ce-9626-4ede0004baa9"
      },
      "id": "jhUe7p_4x9Vb",
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.679347813129425, 0.64402174949646, 0.7146739363670349, 0.6902173757553101, 0.6739130616188049, 0.7038043737411499, 0.6739130616188049, 0.6739130616188049, 0.6603260636329651, 0.6875] \n",
            " 0.680163049697876\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}